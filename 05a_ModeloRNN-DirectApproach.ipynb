{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8e3b633-7855-4d94-ad96-52de05dab5bc",
   "metadata": {},
   "source": [
    "# Predicci√≥n del Color RNN y Desfase Fijo en M√°quinas de Impresi√≥n\n",
    "\n",
    "En este proyecto, cada m√°quina de impresi√≥n tiene un desfase distinto entre el momento en que deposita la tinta sobre el material y el instante en que el sensor de color mide el resultado final. Este desfase depende de la configuraci√≥n f√≠sica de la m√°quina y puede variar en n√∫mero de pasos o momentos temporales.\n",
    "\n",
    "Para estandarizar el proceso en esta tarea, consideraremos un **desfase fijo de 4 pasos** (offset = 4), lo que significa que el color que deseamos predecir en un instante *t* se medir√° realmente en *t+4*. Adem√°s, utilizaremos una **ventana de 20 pasos anteriores** para hacer la predicci√≥n.\n",
    "\n",
    "Esto implica que nuestro modelo debe cumplir con los siguientes criterios:\n",
    "\n",
    "- A cada instante *t*, queremos predecir el color que ser√° medido en *t+4*.\n",
    "- Si offset = 4 pasos, significa que la fila *index=t+4* registrar√° el color correspondiente a la impresi√≥n en *t*.\n",
    "\n",
    "Para manejar este desfase, utilizamos el enfoque conocido como **‚ÄúDirect approach con offset‚Äù**:\n",
    "\n",
    "- No necesitamos un modelo multi-output que genere predicciones para *t+1, t+2, t+3, t+4* y luego seleccionar solo el 4¬∫ valor.\n",
    "- No aplicamos un m√©todo autoregresivo que retroalimente sus propias predicciones en cada paso.\n",
    "- Entrenamos un modelo (por ejemplo, LSTM) que, dada una **ventana previa de 20 pasos** *(t‚àí19..t)*, **prediga directamente el color en *t+4***.\n",
    "\n",
    "## Ventajas y Consideraciones\n",
    "‚úÖ **Ventaja**: Simplifica la arquitectura del modelo y permite concentrar el entrenamiento en exactamente el horizonte que nos interesa.  \n",
    "‚ö†Ô∏è **Desventaja**: No proporciona predicciones intermedias (*t+1, t+2, t+3*), pero esto no es necesario si el sensor mide consistentemente a *t+4*.\n",
    "\n",
    "---\n",
    "\n",
    "## **Diagrama del Flujo de la L√°mina en la M√°quina de Impresi√≥n**\n",
    "                     *(Flujo del material en la l√≠nea de producci√≥n)*\n",
    "     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "\n",
    "     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  distancia \"offset\"                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "     ‚îÇ        ‚îÇ                  (4 pasos en este caso)            ‚îÇ      ‚îÇ\n",
    "     ‚îÇCABEZAL ‚îÇ--------------------------------------------------->‚îÇSENSOR‚îÇ\n",
    "     ‚îÇIMPRENTA‚îÇ                                                    ‚îÇCOLOR ‚îÇ\n",
    "     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "1Ô∏è‚É£ **Cabezales de impresi√≥n**\n",
    "   - En el instante *t*, la m√°quina deposita tinta bajo ciertas condiciones (velocidad, estado de la m√°quina, etc.).\n",
    "   - Estas condiciones influyen en el color resultante que se medir√° m√°s adelante.\n",
    "\n",
    "2Ô∏è‚É£ **Desfase f√≠sico (offset)**\n",
    "   - La l√°mina avanza hasta que el sensor de color puede medirla.\n",
    "   - No se mide inmediatamente el color en *t+1* ni en *t+2*, sino hasta el tiempo *t+4*.\n",
    "\n",
    "3Ô∏è‚É£ **Decisi√≥n de modelado (\"Direct offset = 4\")**\n",
    "   - No es necesario predecir el color en *t+1, t+2, t+3*.\n",
    "   - Nos enfocamos √∫nicamente en predecir el color cuando la tinta llegue al sensor en *t+4*.\n",
    "   - Para ello, entrenamos un modelo que, dada una **ventana de 20 pasos anteriores** *(t‚àí19..t)*, prediga directamente el color en *t+4*.\n",
    "\n",
    "---\n",
    "\n",
    "üìå **Conclusi√≥n**  \n",
    "Cada m√°quina puede tener un offset distinto dependiendo de su configuraci√≥n, pero para esta tarea, **lo hemos estandarizado a 4 pasos** y usaremos **una ventana de 20 pasos anteriores** como entrada del modelo. Esto permite un modelado m√°s eficiente y consistente, facilitando la predicci√≥n precisa del color en la producci√≥n. üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "788e549c-a8af-496c-af4a-ff25897b8e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### RECORDAR CAMBIAR EL ENVIRONMENT A p310_npy1_GPUok_RNN\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import layers, Model, Input, regularizers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2914fce-fead-49a6-ac28-6de669a0187d",
   "metadata": {},
   "source": [
    "# Mirar si tensorflow usar√° GPU\n",
    "\n",
    "Para este modelado de RNN con direct approach, usar√© la librer√≠a Tensorflow. Para verificar que la usar√°:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9454230-1e17-4039-9472-7531849f8ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA disponible: True\n",
      "cuDNN disponible: True\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA disponible:\", tf.test.is_built_with_cuda())\n",
    "print(\"cuDNN disponible:\", tf.test.is_built_with_gpu_support())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dea7cc-04a6-4c97-b7a0-8bfddd42be5c",
   "metadata": {},
   "source": [
    "# Variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "455a2af3-d121-4e57-b13c-abd8252814bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIC_ENTRADA='train_test_val_scaler.joblib'\n",
    "RUTA_FICHEROS = r\"C:\\Users\\jaume\\Documents\\Proyecto\\datos\"\n",
    "FIC_SALIDA='prediccion_rnn_direct.joblib'\n",
    "MEJOR_MODELO='mejor_modelo_rnn_direct_approach.h5'\n",
    "\n",
    "# Par√°metros para la ventana y el horizonte\n",
    "WINDOW_SIZE = 30\n",
    "OFFSET = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15420547-1aba-4404-b91a-103c16f93823",
   "metadata": {},
   "source": [
    "# Semillas de aleatoriedad\n",
    "\n",
    "Para que sea lo m√°s reproducible posible. Aunque ciertas cosas como el **dropout** pueden afectar al resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee135f4f-3d0c-469b-adfe-b7f6a67a6e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 7419\n",
    "\n",
    "# Fijar la semilla en todos los m√≥dulos relevantes\n",
    "#random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'  # Fuerza operaciones deterministas\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'  # Fuerza cuDNN determinista en GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5773fc5d-64a6-4c66-98d8-3b8d84670704",
   "metadata": {},
   "source": [
    "# Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "291e053c-aca2-419a-a134-7d8d6c2a7711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "os.chdir(RUTA_FICHEROS)\n",
    "\n",
    "with open(FIC_ENTRADA, 'rb') as file:\n",
    "    data_dict = joblib.load(file)\n",
    "\n",
    "# Recuperar DataFrame y scaler\n",
    "df_train = data_dict['train'].copy()\n",
    "df_test = data_dict['test'].copy()\n",
    "df_val = data_dict['val'].copy()\n",
    "scaler = data_dict['scaler']              # Contiene las normalizaciones con StandarScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fa83d28-fd45-4db6-9251-1006f43438d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['L_scaled', 'A_scaled', 'B_scaled', 'tiempo_en_estado_scaled',\n",
       "       'velocidad_scaled', 'duracion_parada_robust_scaled', 'patron_0',\n",
       "       'patron_2', 'patron_3', 'patron_4',\n",
       "       ...\n",
       "       'patron_88', 'patron_89', 'patron_90', 'patron_91', 'patron_92',\n",
       "       'patron_93', 'patron_94', 'estado_alta', 'estado_normal',\n",
       "       'estado_puesta'],\n",
       "      dtype='object', length=103)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns\n",
    "df_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d03380a-723d-45cb-8004-1c9b17b85d04",
   "metadata": {},
   "source": [
    "## Defino las columnas target y feature\n",
    "\n",
    "Quitamos la columna *seq_time* ya que a efectos pr√°cticos es un √≠ndice que no aporta valor al modelo, y anteriormente ya la hemos usado para ordenar el dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "028ffda6-4aea-4dca-b0da-b79d0e620691",
   "metadata": {},
   "outputs": [],
   "source": [
    "excluir_columnas = [\"L_scaled\", \"A_scaled\", \"B_scaled\", \"seq_time\"]\n",
    "feature_cols = [col for col in df_train.columns if col not in excluir_columnas]\n",
    "target_cols = [\"L_scaled\",\"A_scaled\",\"B_scaled\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efba7ea-ec9c-4f7d-99cd-60b4b0e104e8",
   "metadata": {},
   "source": [
    "# Crear secuencias (ventanas)\n",
    "\n",
    "**Funci√≥n create_sequences_direct_offset:**\n",
    "\n",
    "Toma un DataFrame ordenado cronol√≥gicamente y genera secuencias de largo window_size a partir de las columnas de entrada (features). El target que se predice es la fila que se encuentra a offset pasos en el futuro respecto al final de la ventana (se selecciona la fila en la posici√≥n i + window_size + offset - 1).\n",
    "\n",
    "**Generaci√≥n de secuencias para cada subconjunto:**\n",
    "\n",
    "Se llama a la funci√≥n para los dataframes de entrenamiento (df_train), validaci√≥n (df_val) y test (df_test), generando as√≠ las matrices X y Y correspondientes para cada uno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "549f10b4-9692-4e00-8565-091d78122485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (216735, 30, 100) Y_train.shape: (216735, 3)\n",
      "X_val.shape:   (27062, 30, 100) Y_val.shape:   (27062, 3)\n",
      "X_test.shape:  (27062, 30, 100) Y_test.shape:  (27062, 3)\n"
     ]
    }
   ],
   "source": [
    "def create_sequences_direct_offset(df, feature_cols, target_cols, \n",
    "                                   window_size=20, offset=4):\n",
    "    \"\"\"\n",
    "    Crea X, Y para un enfoque \"Direct\" a offset pasos en el futuro.\n",
    "    \n",
    "    - X : (N, window_size, n_features)\n",
    "    - Y : (N, n_targets)  # un √∫nico step => offset steps en el futuro\n",
    "    - df: DataFrame ordenado cronol√≥gicamente (por ejemplo, 'seq_time').\n",
    "    \n",
    "    Par√°metros:\n",
    "    -----------\n",
    "      df : pd.DataFrame con las columnas de features + target + orden temporal.\n",
    "      feature_cols : list[str], nombres de las columnas de entrada.\n",
    "      target_cols : list[str], nombres de las columnas del target (ej. [L_scaled,A_scaled,B_scaled]).\n",
    "      window_size : int, cu√°ntas filas usar de hist√≥rico como input.\n",
    "      offset : int, cu√°ntos pasos a futuro se quiere predecir.\n",
    "    \n",
    "    Retorno:\n",
    "    --------\n",
    "      X : np.ndarray de shape (N, window_size, len(feature_cols))\n",
    "      Y : np.ndarray de shape (N, len(target_cols))\n",
    "    \"\"\"\n",
    "\n",
    "    data_features = df[feature_cols].values\n",
    "    data_target   = df[target_cols].values\n",
    "\n",
    "    X_list, Y_list = [], []\n",
    "    n = len(df)\n",
    "\n",
    "    # Se recorre hasta n - window_size - offset + 1 para que siempre exista la secuencia completa\n",
    "    for i in range(n - window_size - offset + 1):\n",
    "        x_seq = data_features[i : i + window_size]\n",
    "        # La fila target es la que se encuentra en: i + window_size + (offset - 1)\n",
    "        y_val = data_target[i + window_size + offset - 1]\n",
    "        \n",
    "        X_list.append(x_seq)\n",
    "        Y_list.append(y_val)\n",
    "    \n",
    "    X_arr = np.array(X_list, dtype=np.float32)\n",
    "    Y_arr = np.array(Y_list, dtype=np.float32)\n",
    "    return X_arr, Y_arr\n",
    "\n",
    "X_train, Y_train = create_sequences_direct_offset(df_train, feature_cols, target_cols, WINDOW_SIZE, OFFSET)\n",
    "X_val,   Y_val   = create_sequences_direct_offset(df_val,   feature_cols, target_cols, WINDOW_SIZE, OFFSET)\n",
    "X_test,  Y_test  = create_sequences_direct_offset(df_test,  feature_cols, target_cols, WINDOW_SIZE, OFFSET)\n",
    "\n",
    "print(\"X_train.shape:\", X_train.shape, \"Y_train.shape:\", Y_train.shape)\n",
    "print(\"X_val.shape:  \", X_val.shape,   \"Y_val.shape:  \", Y_val.shape)\n",
    "print(\"X_test.shape: \", X_test.shape,  \"Y_test.shape: \", Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0855b4-2cc6-4e8e-851a-cb9157d19038",
   "metadata": {},
   "source": [
    "# Optimizar datos para tensorflow\n",
    "\n",
    "## Convertir los datos a tf.float32 (Formato nativo de TensorFlow)\n",
    "\n",
    "TensorFlow maneja mejor float32 en GPUs, ya que float64 usa m√°s memoria sin mejorar el rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92c14ed7-99e7-4fc7-beff-e44228d8b949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir X e Y a tensores de float32\n",
    "X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
    "Y_train = tf.convert_to_tensor(Y_train, dtype=tf.float32)\n",
    "\n",
    "X_val = tf.convert_to_tensor(X_val, dtype=tf.float32)\n",
    "Y_val = tf.convert_to_tensor(Y_val, dtype=tf.float32)\n",
    "\n",
    "X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
    "Y_test = tf.convert_to_tensor(Y_test, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97da8bfc-9b7e-4a04-a2e0-6fed45e96d77",
   "metadata": {},
   "source": [
    "## Verificar el tipo de datos internos (float o int)\n",
    "\n",
    "Si hay datos enteros (int), TensorFlow podr√≠a generar errores en la optimizaci√≥n. Aseg√∫rate de que X tenga solo float32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "167b796c-935d-44e4-bbc7-58f32e18c2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train dtype: <dtype: 'float32'>\n",
      "Y_train dtype: <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train dtype:\", X_train.dtype)\n",
    "print(\"Y_train dtype:\", Y_train.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b55c47c1-27d3-4980-880c-ac4e97caba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.cast(X_train, dtype=tf.float32)\n",
    "Y_train = tf.cast(Y_train, dtype=tf.float32)\n",
    "\n",
    "X_val = tf.cast(X_val, dtype=tf.float32)\n",
    "Y_val = tf.cast(Y_val, dtype=tf.float32)\n",
    "\n",
    "X_test = tf.cast(X_test, dtype=tf.float32)\n",
    "Y_test = tf.cast(Y_test, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e75cb5-94fc-4e97-bdcb-a706dfabd77a",
   "metadata": {},
   "source": [
    "## Usar tf.data.Dataset para mayor eficiencia\n",
    "\n",
    "Si los datos son grandes, es mejor convertirlos en tf.data.Dataset, lo cual optimiza la carga de datos y mejora el rendimiento en la GPU.\n",
    "\n",
    "En mi caso NO los usar√© ya que de momento los datos no son muy grandes y como los agregu√© m√°s tarde, tendr√≠a que introducir muchos cambios en el c√≥digo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fcb1cd6-7688-4725-844a-0a17325a91a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear datasets eficientes para entrenamiento\n",
    "#train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "#val_dataset = tf.data.Dataset.from_tensor_slices((X_val, Y_val)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "#test_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test)).batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2655b7ab-6ec8-4245-b89e-66ed666068e1",
   "metadata": {},
   "source": [
    "# Callback para medir el tiempo por √©poca\n",
    "\n",
    "Medir√© el tiempo de los entrenamientos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0db6b4f9-afb6-4ac8-a65c-66fc46541989",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeHistory(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.times = []\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_start_time = time.time()\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.times.append(time.time() - self.epoch_start_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9199c49c-7580-49b5-9968-39f4b58a0325",
   "metadata": {},
   "source": [
    "# Definir modelo\n",
    "\n",
    "La funci√≥n `build_rnn_direct` crea un modelo con dos capas LSTM o GRU. Al usar `return_sequences=False` en la segunda capa, se obtiene un √∫nico vector de salida. Esto no es un enfoque seq2seq (donde se generar√≠a una secuencia completa de salida).\n",
    "\n",
    "Esta funci√≥n est√° preparada para recibir si queremos usar LSTM o GRU as√≠ podr√© luego en el grid pasarlo como par√°metro tambi√©n, los que recibe par√°metros son:\n",
    "\n",
    "- num_features: n√∫mero de features de entrada.\n",
    "- num_targets: tama√±o del vector de salida.\n",
    "- window_size: longitud de la secuencia de entrada.\n",
    "- latent_dim: n√∫mero de unidades en la capa recurrente.\n",
    "- dropout: fracci√≥n de dropout a aplicar en las celdas recurrentes.\n",
    "- learning_rate: tasa de aprendizaje del optimizador.\n",
    "- cell_type: str, puede ser \"GRU\" o \"LSTM\". Permite elegir la c√©lula recurrente.\n",
    "\n",
    "## Escoger la m√©trica para medir el resultado (bondad)\n",
    "\n",
    "Durante el proceso de validaci√≥n con el cliente, **se ha acordado que la m√©trica de evaluaci√≥n principal ser√° el MSE (Mean Squared Error)**. Se ha considerado que esta funci√≥n de p√©rdida es la m√°s adecuada para el problema, dado que prioriza minimizar los errores grandes en la predicci√≥n de color.\n",
    "La funci√≥n devuelve el modelo a entrenar y las m√©tricas de bondad. Usar√© MSE, aunque tambi√©n calcular√© MAE para comparar. El cliente determina que MSE es suficiente. \n",
    "\n",
    "Otras opciones eran \"Delta E\", \"Cosine Similarity\" pero el cliente por el momento las descarta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7d048c-dcdc-45a7-8286-b0b56ba549f4",
   "metadata": {},
   "source": [
    "## Explicaci√≥n del C√≥digo\n",
    "\n",
    "Este modelo RNN sigue un **enfoque directo** (direct approach), donde la entrada es una ventana de datos hist√≥ricos (`window_size`) y la salida es un **√∫nico vector de predicci√≥n**.  \n",
    "**Este modelo NO es seq2seq**, ya que la salida **no es una secuencia**, sino un **vector √∫nico**.\n",
    "\n",
    "Prob√© un modelo con seq2seq y aunque los resultados no fueron malos, no mejoraban mucho, complicaban el modelo y no creo que sea realmente necesario para este problema.\n",
    "\n",
    "## Par√°metros de entrada de la funci√≥n\n",
    "\n",
    "| Par√°metro       | Descripci√≥n |\n",
    "|----------------|------------|\n",
    "| **`num_features`** | N√∫mero de variables de entrada. |\n",
    "| **`num_targets`** | Dimensi√≥n del vector de salida (para predicci√≥n de colores LAB: 3). |\n",
    "| **`window_size`** | Cantidad de pasos temporales usados en la entrada. |\n",
    "| **`latent_dim`** | N√∫mero de neuronas en cada capa recurrente. |\n",
    "| **`dropout`** | Ratio de dropout para prevenir sobreajuste. |\n",
    "| **`learning_rate`** | Tasa de aprendizaje del optimizador. |\n",
    "| **`cell_type`** | Tipo de celda recurrente: `\"GRU\"` o `\"LSTM\"`. |\n",
    "\n",
    "He probado con GRU y LSTM, no se ve una diferencia muy grande as√≠ que me he quedado con LSTM por estar m√°s probado y ser m√°s robusto.\n",
    "\n",
    "---\n",
    "\n",
    "## ¬øPor qu√© cada decisi√≥n en el modelo?\n",
    "\n",
    "**Elecci√≥n entre LSTM y GRU\n",
    "\n",
    "- **GRU:** M√°s r√°pido y eficiente en memoria.\n",
    "- **LSTM:** M√°s potente para secuencias largas con dependencias temporales.\n",
    "- **El modelo permite seleccionar ambos** (`cell_type`).\n",
    "\n",
    "Como he comentado y ya que he construido la funci√≥n para recibir este par√°metro me he quedado con LSTM.\n",
    "\n",
    "**`return_sequences=True` en la primera capa**\n",
    "\n",
    "- Permite que la segunda capa reciba secuencias completas.\n",
    "- Mejora la representaci√≥n de los datos temporales.\n",
    "\n",
    "He probado con 1, 2 y 3 capas, la que mejores resultados me ha dado es con 2.\n",
    "\n",
    "**`BatchNormalization()`**\n",
    "\n",
    "- Acelera la convergencia.\n",
    "- Evita saturaci√≥n de gradientes.\n",
    "- Mejora estabilidad en el entrenamiento.\n",
    "\n",
    "El modelo se sobreajustaba demasiado, con este par√°metro tambi√©n logro que se estabilice un poco m√°s.\n",
    "\n",
    "**`return_sequences=False` en la segunda capa**\n",
    "\n",
    "- La red solo devuelve **el √∫ltimo estado** para la predicci√≥n.\n",
    "- Evita que el modelo genere una secuencia completa de salida.\n",
    "\n",
    "**`kernel_regularizer=regularizers.l2(1e-4)`**\n",
    "\n",
    "- Evita el sobreajuste limitando la magnitud de los pesos.\n",
    "\n",
    "El modelo se sobreajustaba demasiado, con este par√°metro tambi√©n logro que se estabilice un poco m√°s.\n",
    "\n",
    "**Optimizaci√≥n con Adam (AMSGrad activado)**\n",
    "\n",
    "- **AMSGrad** mejora la estabilidad en la actualizaci√≥n de gradientes.\n",
    "- Reduce el problema de acumulaci√≥n de momento en Adam.\n",
    "- Adem√°s ayuda a la hora de reproducir el mismo entrenamiento\n",
    "\n",
    "**Funci√≥n de p√©rdida y m√©tricas**\n",
    "\n",
    "- **`loss=\"mse\"`**: M√≠nimos cuadrados medios, prioriza la reducci√≥n de grandes errores.\n",
    "- **`metrics=[\"mae\"]`**: Se agrega **MAE** para comparaci√≥n con MSE.\n",
    "- El **MSE** es la m√©trica seleccionada porque a parte de ser la elecci√≥n que tom√≥ la emrpesa para esta prueba de concepto:\n",
    "  - Es la m√°s adecuada para priorizar **errores grandes** en la predicci√≥n de color.\n",
    "  - Minimiza las diferencias absolutas al cuadrado, lo que penaliza m√°s los errores grandes.\n",
    "  - Es **m√°s estable** que m√©tricas como `Cosine Similarity` o `Delta E`, que se descartan por ahora.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f89038a-d3ac-40aa-95c4-15a4e0e39237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rnn_direct(\n",
    "    num_features: int, \n",
    "    num_targets: int = 3, \n",
    "    window_size: int = 20, \n",
    "    latent_dim: int = 64,\n",
    "    dropout: float = 0.4, \n",
    "    learning_rate: float = 1e-4, \n",
    "    cell_type: str = \"GRU\"\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "    Construye un modelo RNN (direct approach) para predecir un √∫nico paso en el futuro.\n",
    "\n",
    "    Este modelo **NO es seq2seq**, ya que devuelve un √∫nico vector de salida en lugar de una secuencia.\n",
    "\n",
    "    Par√°metros:\n",
    "    -----------\n",
    "    - `num_features` (int): N√∫mero de caracter√≠sticas de entrada.\n",
    "    - `num_targets` (int): Dimensi√≥n del vector de salida (por defecto, 3 para predicci√≥n de colores LAB).\n",
    "    - `window_size` (int): Tama√±o de la secuencia de entrada (longitud del hist√≥rico usado para predecir).\n",
    "    - `latent_dim` (int): N√∫mero de unidades en cada capa recurrente.\n",
    "    - `dropout` (float): Ratio de dropout para prevenir sobreajuste en las capas recurrentes.\n",
    "    - `learning_rate` (float): Tasa de aprendizaje del optimizador Adam.\n",
    "    - `cell_type` (str): Tipo de c√©lula recurrente, `\"GRU\"` o `\"LSTM\"`.\n",
    "\n",
    "    Retorna:\n",
    "    -----------\n",
    "    - `tf.keras.Model`: Modelo RNN compilado con optimizador Adam (amsgrad activado).\n",
    "\n",
    "    Notas sobre el modelo:\n",
    "    - Se permite elegir entre GRU y LSTM din√°micamente.\n",
    "    - Se usa **BatchNormalization** despu√©s de la primera capa recurrente para mejorar estabilidad.\n",
    "    - La segunda capa recurrente **no devuelve secuencias** (`return_sequences=False`).\n",
    "    - Se aplica regularizaci√≥n L2 para evitar sobreajuste en los pesos de la red.\n",
    "    - El optimizador **Adam con AMSGrad** se usa para una convergencia m√°s estable.\n",
    "    \"\"\"\n",
    "    \n",
    "    # üîπ Definir la arquitectura secuencial\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Input(shape=(window_size, num_features))  # Entrada con formato (time_steps, features)\n",
    "    ])\n",
    "\n",
    "    # üîπ Selecci√≥n de la c√©lula recurrente\n",
    "    if cell_type.upper() == \"GRU\":\n",
    "        rnn_layer = layers.GRU\n",
    "    elif cell_type.upper() == \"LSTM\":\n",
    "        rnn_layer = layers.LSTM\n",
    "    else:\n",
    "        raise ValueError(\"Error: 'cell_type' debe ser 'GRU' o 'LSTM'.\")\n",
    "\n",
    "    # üîπ Primera capa recurrente: \n",
    "    # - Devuelve secuencias para permitir el paso de informaci√≥n a la siguiente capa.\n",
    "    # - Se aplica dropout para regularizaci√≥n.\n",
    "    model.add(rnn_layer(latent_dim, return_sequences=True, dropout=dropout))\n",
    "\n",
    "    # üîπ Normalizaci√≥n para estabilizar entrenamiento y acelerar convergencia\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    # üîπ Segunda capa recurrente: \n",
    "    # - Devuelve solo el estado final (`return_sequences=False`).\n",
    "    # - Se aplica regularizaci√≥n L2 para evitar sobreajuste en los pesos.\n",
    "    model.add(rnn_layer(latent_dim, return_sequences=False, dropout=dropout,\n",
    "                        kernel_regularizer=regularizers.l2(1e-4)))\n",
    "\n",
    "    # üîπ Capa densa de salida: \n",
    "    # - Predice los valores de salida (num_targets).\n",
    "    model.add(layers.Dense(num_targets))\n",
    "\n",
    "    # üîπ Configurar el optimizador Adam con AMSGrad activado\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, amsgrad=True)\n",
    "\n",
    "    # üîπ Compilar el modelo con MSE como funci√≥n de p√©rdida y MAE como m√©trica adicional\n",
    "    model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d78695-3d74-4745-adef-5781ecf1fbae",
   "metadata": {},
   "source": [
    "# Par√°metros para grid search\n",
    "\n",
    "Defino los par√°metros a cruzar y una lista para meter los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f7cda0e-61fa-4010-aabf-985917951bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = {\n",
    "    \"latent_dim\": [32, 16],\n",
    "    #\"dropout\": [0.4, 0.6],\n",
    "    \"dropout\": [0.7, 0.8],\n",
    "    \"learning_rate\": [1e-4, 1e-5],\n",
    "    \"batch_size\": [32, 64],\n",
    "    #\"cell_type\": [\"GRU\", \"LSTM\"]  # Probar ambas c√©lulas\n",
    "    \"cell_type\": [\"LSTM\"]\n",
    "}\n",
    "\n",
    "results_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762e769c-2a29-4125-bc43-96defb9eaf1f",
   "metadata": {},
   "source": [
    "# Entrenar el modelo\n",
    "\n",
    "Aqu√≠ creo un bucle `for` que:\n",
    "\n",
    "- Itera sobre todas las combinaciones de hiperpar√°metros definidos en el grid.\n",
    "- Defino los callbacks `EarlyStopping`, `ReduceLROnPlateau` y `TimeHistory`, este √∫ltimo es una clase definida por mi para poder medir el tiempo de los entrenamientos.\n",
    "- Entreno el modelo con `fit`.\n",
    "- Los resultados los voy guardando en una lista que luego incorporar√© a un dataframe que finalmente en pasos siguientes ser√° evaluado y guardado en un fichero *joblib*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39a4200-f633-4a18-9ea8-35dbc5e991c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando con: latent_dim=32, dropout=0.7, learning_rate=0.0001, batch_size=32, cell_type=LSTM\n",
      "Epoch 1/100\n",
      "6773/6773 [==============================] - 95s 13ms/step - loss: 0.7178 - mae: 0.6612 - val_loss: 0.6714 - val_mae: 0.6331 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "6773/6773 [==============================] - 91s 13ms/step - loss: 0.5432 - mae: 0.5558 - val_loss: 1.1629 - val_mae: 0.8514 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "6772/6773 [============================>.] - ETA: 0s - loss: 0.4443 - mae: 0.4995\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "6773/6773 [==============================] - 91s 13ms/step - loss: 0.4442 - mae: 0.4995 - val_loss: 1.2658 - val_mae: 0.9011 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "6773/6773 [==============================] - 92s 14ms/step - loss: 0.4116 - mae: 0.4861 - val_loss: 1.3188 - val_mae: 0.9229 - lr: 5.0000e-05\n",
      "Epoch 5/100\n",
      "6772/6773 [============================>.] - ETA: 0s - loss: 0.3089 - mae: 0.4117\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "6773/6773 [==============================] - 91s 13ms/step - loss: 0.3089 - mae: 0.4117 - val_loss: 1.4454 - val_mae: 0.9649 - lr: 5.0000e-05\n",
      "Epoch 6/100\n",
      "6773/6773 [==============================] - 92s 14ms/step - loss: 0.2963 - mae: 0.4019 - val_loss: 1.4305 - val_mae: 0.9787 - lr: 2.5000e-05\n",
      "Epoch 7/100\n",
      "6770/6773 [============================>.] - ETA: 0s - loss: 0.2691 - mae: 0.3786\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "6773/6773 [==============================] - 93s 14ms/step - loss: 0.2690 - mae: 0.3786 - val_loss: 1.4953 - val_mae: 1.0023 - lr: 2.5000e-05\n",
      "Epoch 8/100\n",
      "6773/6773 [==============================] - 92s 14ms/step - loss: 0.2688 - mae: 0.3774 - val_loss: 1.4781 - val_mae: 0.9978 - lr: 1.2500e-05\n",
      "Epoch 9/100\n",
      "6773/6773 [==============================] - ETA: 0s - loss: 0.2531 - mae: 0.3647\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "6773/6773 [==============================] - 92s 14ms/step - loss: 0.2531 - mae: 0.3647 - val_loss: 1.4723 - val_mae: 0.9992 - lr: 1.2500e-05\n",
      "Epoch 10/100\n",
      "6773/6773 [==============================] - 90s 13ms/step - loss: 0.2535 - mae: 0.3643 - val_loss: 1.4616 - val_mae: 0.9973 - lr: 6.2500e-06\n",
      "Epoch 11/100\n",
      "6772/6773 [============================>.] - ETA: 0s - loss: 0.2444 - mae: 0.3563\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "6773/6773 [==============================] - 91s 13ms/step - loss: 0.2443 - mae: 0.3563 - val_loss: 1.4428 - val_mae: 0.9938 - lr: 6.2500e-06\n",
      "  -> best_val_mse (history): 0.671392 encontrado en la permutaci√≥n: 1 , best_val_mse (evaluated): 0.671392, best_train_mse (evaluated): 1.132948, best_val_mae: 0.633077, epochs: 11, total_time: 1013.11s\n",
      "Entrenando con: latent_dim=32, dropout=0.7, learning_rate=0.0001, batch_size=64, cell_type=LSTM\n",
      "Epoch 1/100\n",
      "3387/3387 [==============================] - 50s 14ms/step - loss: 0.8956 - mae: 0.7646 - val_loss: 1.1010 - val_mae: 0.8901 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 0.6046 - mae: 0.6026 - val_loss: 1.4266 - val_mae: 0.9418 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "3385/3387 [============================>.] - ETA: 0s - loss: 0.4830 - mae: 0.5285\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 0.4828 - mae: 0.5284 - val_loss: 1.4900 - val_mae: 0.9767 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "3387/3387 [==============================] - 48s 14ms/step - loss: 0.4370 - mae: 0.5005 - val_loss: 1.4235 - val_mae: 0.9587 - lr: 5.0000e-05\n",
      "Epoch 5/100\n",
      "3387/3387 [==============================] - ETA: 0s - loss: 0.3881 - mae: 0.4663\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "3387/3387 [==============================] - 48s 14ms/step - loss: 0.3881 - mae: 0.4663 - val_loss: 1.4411 - val_mae: 0.9651 - lr: 5.0000e-05\n",
      "Epoch 6/100\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 0.3675 - mae: 0.4530 - val_loss: 1.4004 - val_mae: 0.9569 - lr: 2.5000e-05\n",
      "Epoch 7/100\n",
      "3384/3387 [============================>.] - ETA: 0s - loss: 0.3473 - mae: 0.4384\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "3387/3387 [==============================] - 48s 14ms/step - loss: 0.3471 - mae: 0.4383 - val_loss: 1.4169 - val_mae: 0.9668 - lr: 2.5000e-05\n",
      "Epoch 8/100\n",
      "3387/3387 [==============================] - 48s 14ms/step - loss: 0.3385 - mae: 0.4332 - val_loss: 1.3542 - val_mae: 0.9426 - lr: 1.2500e-05\n",
      "Epoch 9/100\n",
      "3386/3387 [============================>.] - ETA: 0s - loss: 0.3289 - mae: 0.4257\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 0.3289 - mae: 0.4257 - val_loss: 1.3649 - val_mae: 0.9470 - lr: 1.2500e-05\n",
      "Epoch 10/100\n",
      "3387/3387 [==============================] - 48s 14ms/step - loss: 0.3237 - mae: 0.4225 - val_loss: 1.3313 - val_mae: 0.9368 - lr: 6.2500e-06\n",
      "Epoch 11/100\n",
      "3384/3387 [============================>.] - ETA: 0s - loss: 0.3190 - mae: 0.4187\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "3387/3387 [==============================] - 48s 14ms/step - loss: 0.3189 - mae: 0.4185 - val_loss: 1.3383 - val_mae: 0.9396 - lr: 6.2500e-06\n",
      "  -> best_val_mse (history): 1.100957 encontrado en la permutaci√≥n: 1 , best_val_mse (evaluated): 1.100957, best_train_mse (evaluated): 0.917688, best_val_mae: 0.890092, epochs: 11, total_time: 525.39s\n",
      "Entrenando con: latent_dim=32, dropout=0.7, learning_rate=1e-05, batch_size=32, cell_type=LSTM\n",
      "Epoch 1/100\n",
      "6773/6773 [==============================] - 97s 14ms/step - loss: 1.0880 - mae: 0.8677 - val_loss: 0.7422 - val_mae: 0.7317 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "6773/6773 [==============================] - 94s 14ms/step - loss: 1.0284 - mae: 0.8432 - val_loss: 0.7008 - val_mae: 0.7135 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "6773/6773 [==============================] - 92s 14ms/step - loss: 0.9815 - mae: 0.8230 - val_loss: 0.6894 - val_mae: 0.7051 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "6773/6773 [==============================] - 91s 13ms/step - loss: 0.9430 - mae: 0.8054 - val_loss: 0.7125 - val_mae: 0.7107 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "6773/6773 [==============================] - ETA: 0s - loss: 0.9133 - mae: 0.7905\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "6773/6773 [==============================] - 91s 13ms/step - loss: 0.9133 - mae: 0.7905 - val_loss: 0.7612 - val_mae: 0.7207 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "6773/6773 [==============================] - 92s 14ms/step - loss: 0.8927 - mae: 0.7802 - val_loss: 0.7817 - val_mae: 0.7261 - lr: 5.0000e-06\n",
      "Epoch 7/100\n",
      "6770/6773 [============================>.] - ETA: 0s - loss: 0.8805 - mae: 0.7735\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "6773/6773 [==============================] - 92s 14ms/step - loss: 0.8803 - mae: 0.7734 - val_loss: 0.8088 - val_mae: 0.7306 - lr: 5.0000e-06\n",
      "Epoch 8/100\n",
      "6773/6773 [==============================] - 93s 14ms/step - loss: 0.8694 - mae: 0.7681 - val_loss: 0.8205 - val_mae: 0.7336 - lr: 2.5000e-06\n",
      "Epoch 9/100\n",
      "6770/6773 [============================>.] - ETA: 0s - loss: 0.8620 - mae: 0.7639\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "6773/6773 [==============================] - 92s 14ms/step - loss: 0.8617 - mae: 0.7637 - val_loss: 0.8335 - val_mae: 0.7358 - lr: 2.5000e-06\n",
      "Epoch 10/100\n",
      "6773/6773 [==============================] - 93s 14ms/step - loss: 0.8569 - mae: 0.7612 - val_loss: 0.8389 - val_mae: 0.7368 - lr: 1.2500e-06\n",
      "Epoch 11/100\n",
      "6772/6773 [============================>.] - ETA: 0s - loss: 0.8529 - mae: 0.7588\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "6773/6773 [==============================] - 93s 14ms/step - loss: 0.8529 - mae: 0.7588 - val_loss: 0.8456 - val_mae: 0.7383 - lr: 1.2500e-06\n",
      "Epoch 12/100\n",
      "6773/6773 [==============================] - 93s 14ms/step - loss: 0.8502 - mae: 0.7573 - val_loss: 0.8507 - val_mae: 0.7390 - lr: 1.0000e-06\n",
      "Epoch 13/100\n",
      "6773/6773 [==============================] - 93s 14ms/step - loss: 0.8461 - mae: 0.7552 - val_loss: 0.8565 - val_mae: 0.7401 - lr: 1.0000e-06\n",
      "  -> best_val_mse (history): 0.689429 encontrado en la permutaci√≥n: 3 , best_val_mse (evaluated): 0.689429, best_train_mse (evaluated): 0.904559, best_val_mae: 0.705087, epochs: 13, total_time: 1205.62s\n",
      "Entrenando con: latent_dim=32, dropout=0.7, learning_rate=1e-05, batch_size=64, cell_type=LSTM\n",
      "Epoch 1/100\n",
      "3387/3387 [==============================] - 51s 14ms/step - loss: 1.1032 - mae: 0.8767 - val_loss: 0.7367 - val_mae: 0.7463 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 1.0508 - mae: 0.8550 - val_loss: 0.7163 - val_mae: 0.7401 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "3387/3387 [==============================] - 48s 14ms/step - loss: 1.0142 - mae: 0.8389 - val_loss: 0.7233 - val_mae: 0.7449 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "3386/3387 [============================>.] - ETA: 0s - loss: 0.9827 - mae: 0.8245\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 0.9827 - mae: 0.8245 - val_loss: 0.7510 - val_mae: 0.7549 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "3387/3387 [==============================] - 48s 14ms/step - loss: 0.9571 - mae: 0.8128 - val_loss: 0.7700 - val_mae: 0.7628 - lr: 5.0000e-06\n",
      "Epoch 6/100\n",
      "3386/3387 [============================>.] - ETA: 0s - loss: 0.9430 - mae: 0.8059\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 0.9430 - mae: 0.8059 - val_loss: 0.7920 - val_mae: 0.7719 - lr: 5.0000e-06\n",
      "Epoch 7/100\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 0.9314 - mae: 0.8003 - val_loss: 0.8031 - val_mae: 0.7762 - lr: 2.5000e-06\n",
      "Epoch 8/100\n",
      "3384/3387 [============================>.] - ETA: 0s - loss: 0.9264 - mae: 0.7977\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 0.9260 - mae: 0.7976 - val_loss: 0.8143 - val_mae: 0.7805 - lr: 2.5000e-06\n",
      "Epoch 9/100\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 0.9194 - mae: 0.7942 - val_loss: 0.8206 - val_mae: 0.7826 - lr: 1.2500e-06\n",
      "Epoch 10/100\n",
      "3385/3387 [============================>.] - ETA: 0s - loss: 0.9157 - mae: 0.7924\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 0.9155 - mae: 0.7923 - val_loss: 0.8264 - val_mae: 0.7846 - lr: 1.2500e-06\n",
      "Epoch 11/100\n",
      "3387/3387 [==============================] - 46s 14ms/step - loss: 0.9122 - mae: 0.7907 - val_loss: 0.8307 - val_mae: 0.7859 - lr: 1.0000e-06\n",
      "Epoch 12/100\n",
      "3387/3387 [==============================] - 46s 14ms/step - loss: 0.9097 - mae: 0.7891 - val_loss: 0.8372 - val_mae: 0.7882 - lr: 1.0000e-06\n",
      "  -> best_val_mse (history): 0.716315 encontrado en la permutaci√≥n: 2 , best_val_mse (evaluated): 0.716315, best_train_mse (evaluated): 0.939874, best_val_mae: 0.740129, epochs: 12, total_time: 569.78s\n",
      "Entrenando con: latent_dim=32, dropout=0.8, learning_rate=0.0001, batch_size=32, cell_type=LSTM\n",
      "Epoch 1/100\n",
      "6773/6773 [==============================] - 96s 14ms/step - loss: 0.7708 - mae: 0.6909 - val_loss: 1.0994 - val_mae: 0.8438 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "6773/6773 [==============================] - 93s 14ms/step - loss: 0.5991 - mae: 0.5903 - val_loss: 1.3285 - val_mae: 0.9479 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "6772/6773 [============================>.] - ETA: 0s - loss: 0.4600 - mae: 0.5047\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "6773/6773 [==============================] - 94s 14ms/step - loss: 0.4599 - mae: 0.5046 - val_loss: 1.6617 - val_mae: 1.0885 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "6773/6773 [==============================] - 90s 13ms/step - loss: 0.4055 - mae: 0.4740 - val_loss: 1.5309 - val_mae: 1.0594 - lr: 5.0000e-05\n",
      "Epoch 5/100\n",
      "6771/6773 [============================>.] - ETA: 0s - loss: 0.3466 - mae: 0.4349\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "6773/6773 [==============================] - 91s 13ms/step - loss: 0.3465 - mae: 0.4348 - val_loss: 1.5040 - val_mae: 1.0408 - lr: 5.0000e-05\n",
      "Epoch 6/100\n",
      "6773/6773 [==============================] - 92s 14ms/step - loss: 0.3228 - mae: 0.4195 - val_loss: 1.3717 - val_mae: 0.9973 - lr: 2.5000e-05\n",
      "Epoch 7/100\n",
      "6772/6773 [============================>.] - ETA: 0s - loss: 0.2994 - mae: 0.4017\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "6773/6773 [==============================] - 92s 14ms/step - loss: 0.2994 - mae: 0.4017 - val_loss: 1.3705 - val_mae: 0.9973 - lr: 2.5000e-05\n",
      "Epoch 8/100\n",
      "6773/6773 [==============================] - 92s 14ms/step - loss: 0.2885 - mae: 0.3943 - val_loss: 1.3960 - val_mae: 1.0046 - lr: 1.2500e-05\n",
      "Epoch 9/100\n",
      "6772/6773 [============================>.] - ETA: 0s - loss: 0.2791 - mae: 0.3867\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "6773/6773 [==============================] - 93s 14ms/step - loss: 0.2791 - mae: 0.3867 - val_loss: 1.3979 - val_mae: 1.0060 - lr: 1.2500e-05\n",
      "Epoch 10/100\n",
      "6773/6773 [==============================] - 93s 14ms/step - loss: 0.2754 - mae: 0.3841 - val_loss: 1.4392 - val_mae: 1.0156 - lr: 6.2500e-06\n",
      "Epoch 11/100\n",
      "6772/6773 [============================>.] - ETA: 0s - loss: 0.2705 - mae: 0.3801\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "6773/6773 [==============================] - 91s 13ms/step - loss: 0.2704 - mae: 0.3801 - val_loss: 1.4475 - val_mae: 1.0182 - lr: 6.2500e-06\n",
      "  -> best_val_mse (history): 1.099415 encontrado en la permutaci√≥n: 1 , best_val_mse (evaluated): 1.099415, best_train_mse (evaluated): 0.953295, best_val_mae: 0.843763, epochs: 11, total_time: 1017.33s\n",
      "Entrenando con: latent_dim=32, dropout=0.8, learning_rate=0.0001, batch_size=64, cell_type=LSTM\n",
      "Epoch 1/100\n",
      "3387/3387 [==============================] - 50s 14ms/step - loss: 0.9861 - mae: 0.8152 - val_loss: 1.0177 - val_mae: 0.8060 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 0.7807 - mae: 0.6984 - val_loss: 1.0315 - val_mae: 0.7842 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "3386/3387 [============================>.] - ETA: 0s - loss: 0.5806 - mae: 0.5898\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 0.5805 - mae: 0.5897 - val_loss: 1.4711 - val_mae: 0.9547 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "3387/3387 [==============================] - 48s 14ms/step - loss: 0.5113 - mae: 0.5551 - val_loss: 1.6056 - val_mae: 0.9679 - lr: 5.0000e-05\n",
      "Epoch 5/100\n",
      "3385/3387 [============================>.] - ETA: 0s - loss: 0.4578 - mae: 0.5198\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "3387/3387 [==============================] - 48s 14ms/step - loss: 0.4577 - mae: 0.5196 - val_loss: 1.5771 - val_mae: 0.9667 - lr: 5.0000e-05\n",
      "Epoch 6/100\n",
      "3387/3387 [==============================] - 48s 14ms/step - loss: 0.4420 - mae: 0.5063 - val_loss: 1.6628 - val_mae: 1.0032 - lr: 2.5000e-05\n",
      "Epoch 7/100\n",
      "3384/3387 [============================>.] - ETA: 0s - loss: 0.4188 - mae: 0.4907\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "3387/3387 [==============================] - 48s 14ms/step - loss: 0.4185 - mae: 0.4905 - val_loss: 1.6524 - val_mae: 0.9972 - lr: 2.5000e-05\n",
      "Epoch 8/100\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 0.4116 - mae: 0.4835 - val_loss: 1.6674 - val_mae: 0.9940 - lr: 1.2500e-05\n",
      "Epoch 9/100\n",
      "3384/3387 [============================>.] - ETA: 0s - loss: 0.4009 - mae: 0.4766\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 0.4007 - mae: 0.4764 - val_loss: 1.6786 - val_mae: 0.9935 - lr: 1.2500e-05\n",
      "Epoch 10/100\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 0.3949 - mae: 0.4713 - val_loss: 1.6842 - val_mae: 0.9936 - lr: 6.2500e-06\n",
      "Epoch 11/100\n",
      "3386/3387 [============================>.] - ETA: 0s - loss: 0.3893 - mae: 0.4676\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 0.3892 - mae: 0.4675 - val_loss: 1.6914 - val_mae: 0.9953 - lr: 6.2500e-06\n",
      "  -> best_val_mse (history): 1.017655 encontrado en la permutaci√≥n: 1 , best_val_mse (evaluated): 1.017655, best_train_mse (evaluated): 0.870628, best_val_mae: 0.784157, epochs: 11, total_time: 524.61s\n",
      "Entrenando con: latent_dim=32, dropout=0.8, learning_rate=1e-05, batch_size=32, cell_type=LSTM\n",
      "Epoch 1/100\n",
      "6773/6773 [==============================] - 95s 14ms/step - loss: 1.1103 - mae: 0.8720 - val_loss: 0.7130 - val_mae: 0.7094 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "6773/6773 [==============================] - 93s 14ms/step - loss: 1.0668 - mae: 0.8559 - val_loss: 0.6877 - val_mae: 0.7114 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "6773/6773 [==============================] - 92s 14ms/step - loss: 1.0393 - mae: 0.8459 - val_loss: 0.6624 - val_mae: 0.7017 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "6773/6773 [==============================] - 92s 14ms/step - loss: 1.0035 - mae: 0.8318 - val_loss: 0.6614 - val_mae: 0.6915 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "6773/6773 [==============================] - 92s 14ms/step - loss: 0.9733 - mae: 0.8195 - val_loss: 0.6902 - val_mae: 0.6979 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "6773/6773 [==============================] - ETA: 0s - loss: 0.9501 - mae: 0.8091\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "6773/6773 [==============================] - 92s 14ms/step - loss: 0.9501 - mae: 0.8091 - val_loss: 0.7141 - val_mae: 0.7075 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "6773/6773 [==============================] - 91s 13ms/step - loss: 0.9372 - mae: 0.8031 - val_loss: 0.7293 - val_mae: 0.7147 - lr: 5.0000e-06\n",
      "Epoch 8/100\n",
      "6772/6773 [============================>.] - ETA: 0s - loss: 0.9263 - mae: 0.7982\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "6773/6773 [==============================] - 93s 14ms/step - loss: 0.9262 - mae: 0.7982 - val_loss: 0.7385 - val_mae: 0.7191 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "6773/6773 [==============================] - 93s 14ms/step - loss: 0.9193 - mae: 0.7949 - val_loss: 0.7431 - val_mae: 0.7216 - lr: 2.5000e-06\n",
      "Epoch 10/100\n",
      "6769/6773 [============================>.] - ETA: 0s - loss: 0.9142 - mae: 0.7925\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "6773/6773 [==============================] - 93s 14ms/step - loss: 0.9138 - mae: 0.7923 - val_loss: 0.7486 - val_mae: 0.7245 - lr: 2.5000e-06\n",
      "Epoch 11/100\n",
      "6773/6773 [==============================] - 94s 14ms/step - loss: 0.9094 - mae: 0.7899 - val_loss: 0.7521 - val_mae: 0.7262 - lr: 1.2500e-06\n",
      "Epoch 12/100\n",
      "6773/6773 [==============================] - ETA: 0s - loss: 0.9072 - mae: 0.7889\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "6773/6773 [==============================] - 94s 14ms/step - loss: 0.9072 - mae: 0.7889 - val_loss: 0.7555 - val_mae: 0.7278 - lr: 1.2500e-06\n",
      "Epoch 13/100\n",
      "6773/6773 [==============================] - 94s 14ms/step - loss: 0.9038 - mae: 0.7872 - val_loss: 0.7585 - val_mae: 0.7294 - lr: 1.0000e-06\n",
      "Epoch 14/100\n",
      "6773/6773 [==============================] - 92s 14ms/step - loss: 0.9014 - mae: 0.7861 - val_loss: 0.7622 - val_mae: 0.7313 - lr: 1.0000e-06\n",
      "  -> best_val_mse (history): 0.661415 encontrado en la permutaci√≥n: 4 , best_val_mse (evaluated): 0.661415, best_train_mse (evaluated): 0.976169, best_val_mae: 0.691540, epochs: 14, total_time: 1298.87s\n",
      "Entrenando con: latent_dim=32, dropout=0.8, learning_rate=1e-05, batch_size=64, cell_type=LSTM\n",
      "Epoch 1/100\n",
      "3387/3387 [==============================] - 51s 14ms/step - loss: 1.1285 - mae: 0.8864 - val_loss: 0.8064 - val_mae: 0.7678 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 1.0933 - mae: 0.8707 - val_loss: 0.7700 - val_mae: 0.7566 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "3387/3387 [==============================] - 48s 14ms/step - loss: 1.0723 - mae: 0.8615 - val_loss: 0.7608 - val_mae: 0.7544 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "3387/3387 [==============================] - 48s 14ms/step - loss: 1.0542 - mae: 0.8537 - val_loss: 0.7637 - val_mae: 0.7560 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "3386/3387 [============================>.] - ETA: 0s - loss: 1.0350 - mae: 0.8458\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "3387/3387 [==============================] - 48s 14ms/step - loss: 1.0350 - mae: 0.8458 - val_loss: 0.7779 - val_mae: 0.7606 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "3387/3387 [==============================] - 48s 14ms/step - loss: 1.0174 - mae: 0.8383 - val_loss: 0.7924 - val_mae: 0.7649 - lr: 5.0000e-06\n",
      "Epoch 7/100\n",
      "3385/3387 [============================>.] - ETA: 0s - loss: 1.0071 - mae: 0.8336\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "3387/3387 [==============================] - 49s 14ms/step - loss: 1.0069 - mae: 0.8336 - val_loss: 0.8128 - val_mae: 0.7715 - lr: 5.0000e-06\n",
      "Epoch 8/100\n",
      "3387/3387 [==============================] - 48s 14ms/step - loss: 0.9983 - mae: 0.8295 - val_loss: 0.8256 - val_mae: 0.7755 - lr: 2.5000e-06\n",
      "Epoch 9/100\n",
      "3385/3387 [============================>.] - ETA: 0s - loss: 0.9925 - mae: 0.8273\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "3387/3387 [==============================] - 48s 14ms/step - loss: 0.9923 - mae: 0.8272 - val_loss: 0.8405 - val_mae: 0.7805 - lr: 2.5000e-06\n",
      "Epoch 10/100\n",
      "3387/3387 [==============================] - 48s 14ms/step - loss: 0.9863 - mae: 0.8247 - val_loss: 0.8475 - val_mae: 0.7824 - lr: 1.2500e-06\n",
      "Epoch 11/100\n",
      "3386/3387 [============================>.] - ETA: 0s - loss: 0.9843 - mae: 0.8236\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "3387/3387 [==============================] - 48s 14ms/step - loss: 0.9842 - mae: 0.8235 - val_loss: 0.8552 - val_mae: 0.7846 - lr: 1.2500e-06\n",
      "Epoch 12/100\n",
      "3387/3387 [==============================] - 48s 14ms/step - loss: 0.9806 - mae: 0.8219 - val_loss: 0.8621 - val_mae: 0.7867 - lr: 1.0000e-06\n",
      "Epoch 13/100\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 0.9789 - mae: 0.8209 - val_loss: 0.8694 - val_mae: 0.7889 - lr: 1.0000e-06\n",
      "  -> best_val_mse (history): 0.760756 encontrado en la permutaci√≥n: 3 , best_val_mse (evaluated): 0.760756, best_train_mse (evaluated): 0.986668, best_val_mae: 0.754369, epochs: 13, total_time: 627.86s\n",
      "Entrenando con: latent_dim=16, dropout=0.7, learning_rate=0.0001, batch_size=32, cell_type=LSTM\n",
      "Epoch 1/100\n",
      "6773/6773 [==============================] - 97s 14ms/step - loss: 0.8852 - mae: 0.7537 - val_loss: 0.8439 - val_mae: 0.7980 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "6773/6773 [==============================] - 92s 14ms/step - loss: 0.6874 - mae: 0.6374 - val_loss: 1.1915 - val_mae: 0.9418 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "6769/6773 [============================>.] - ETA: 0s - loss: 0.5347 - mae: 0.5559\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "6773/6773 [==============================] - 93s 14ms/step - loss: 0.5344 - mae: 0.5557 - val_loss: 1.4310 - val_mae: 0.9940 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "6773/6773 [==============================] - 93s 14ms/step - loss: 0.4949 - mae: 0.5385 - val_loss: 1.4812 - val_mae: 1.0074 - lr: 5.0000e-05\n",
      "Epoch 5/100\n",
      "6772/6773 [============================>.] - ETA: 0s - loss: 0.4416 - mae: 0.5046\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "6773/6773 [==============================] - 92s 14ms/step - loss: 0.4416 - mae: 0.5046 - val_loss: 1.5390 - val_mae: 1.0205 - lr: 5.0000e-05\n",
      "Epoch 6/100\n",
      "6773/6773 [==============================] - 92s 14ms/step - loss: 0.4381 - mae: 0.5023 - val_loss: 1.5517 - val_mae: 1.0151 - lr: 2.5000e-05\n",
      "Epoch 7/100\n",
      "6773/6773 [==============================] - ETA: 0s - loss: 0.4145 - mae: 0.4867\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "6773/6773 [==============================] - 92s 14ms/step - loss: 0.4145 - mae: 0.4867 - val_loss: 1.5630 - val_mae: 1.0160 - lr: 2.5000e-05\n",
      "Epoch 8/100\n",
      "6773/6773 [==============================] - 94s 14ms/step - loss: 0.4136 - mae: 0.4862 - val_loss: 1.5402 - val_mae: 1.0126 - lr: 1.2500e-05\n",
      "Epoch 9/100\n",
      "6770/6773 [============================>.] - ETA: 0s - loss: 0.3983 - mae: 0.4760\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "6773/6773 [==============================] - 94s 14ms/step - loss: 0.3982 - mae: 0.4758 - val_loss: 1.5312 - val_mae: 1.0120 - lr: 1.2500e-05\n",
      "Epoch 10/100\n",
      "6773/6773 [==============================] - 92s 14ms/step - loss: 0.3975 - mae: 0.4759 - val_loss: 1.5077 - val_mae: 1.0109 - lr: 6.2500e-06\n",
      "Epoch 11/100\n",
      "6773/6773 [==============================] - ETA: 0s - loss: 0.3880 - mae: 0.4692\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "6773/6773 [==============================] - 92s 14ms/step - loss: 0.3880 - mae: 0.4692 - val_loss: 1.5082 - val_mae: 1.0127 - lr: 6.2500e-06\n",
      "  -> best_val_mse (history): 0.843937 encontrado en la permutaci√≥n: 1 , best_val_mse (evaluated): 0.843937, best_train_mse (evaluated): 0.821814, best_val_mae: 0.798040, epochs: 11, total_time: 1022.87s\n",
      "Entrenando con: latent_dim=16, dropout=0.7, learning_rate=0.0001, batch_size=64, cell_type=LSTM\n",
      "Epoch 1/100\n",
      "3387/3387 [==============================] - 51s 14ms/step - loss: 0.9821 - mae: 0.8183 - val_loss: 0.7399 - val_mae: 0.7095 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 0.7868 - mae: 0.7182 - val_loss: 0.9083 - val_mae: 0.7481 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "3386/3387 [============================>.] - ETA: 0s - loss: 0.6287 - mae: 0.6195\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 0.6286 - mae: 0.6194 - val_loss: 0.9368 - val_mae: 0.7505 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 0.5503 - mae: 0.5762 - val_loss: 0.9640 - val_mae: 0.7674 - lr: 5.0000e-05\n",
      "Epoch 5/100\n",
      "3384/3387 [============================>.] - ETA: 0s - loss: 0.4996 - mae: 0.5447\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 0.4993 - mae: 0.5445 - val_loss: 1.0081 - val_mae: 0.7940 - lr: 5.0000e-05\n",
      "Epoch 6/100\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 0.4660 - mae: 0.5219 - val_loss: 1.0718 - val_mae: 0.8214 - lr: 2.5000e-05\n",
      "Epoch 7/100\n",
      "3387/3387 [==============================] - ETA: 0s - loss: 0.4455 - mae: 0.5076\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 0.4455 - mae: 0.5076 - val_loss: 1.1061 - val_mae: 0.8349 - lr: 2.5000e-05\n",
      "Epoch 8/100\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 0.4310 - mae: 0.4970 - val_loss: 1.1359 - val_mae: 0.8458 - lr: 1.2500e-05\n",
      "Epoch 9/100\n",
      "3387/3387 [==============================] - ETA: 0s - loss: 0.4215 - mae: 0.4903\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 0.4215 - mae: 0.4903 - val_loss: 1.1482 - val_mae: 0.8515 - lr: 1.2500e-05\n",
      "Epoch 10/100\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 0.4150 - mae: 0.4860 - val_loss: 1.1578 - val_mae: 0.8566 - lr: 6.2500e-06\n",
      "Epoch 11/100\n",
      "3386/3387 [============================>.] - ETA: 0s - loss: 0.4102 - mae: 0.4828\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 0.4102 - mae: 0.4827 - val_loss: 1.1643 - val_mae: 0.8597 - lr: 6.2500e-06\n",
      "  -> best_val_mse (history): 0.739947 encontrado en la permutaci√≥n: 1 , best_val_mse (evaluated): 0.739942, best_train_mse (evaluated): 0.789132, best_val_mae: 0.709542, epochs: 11, total_time: 522.75s\n",
      "Entrenando con: latent_dim=16, dropout=0.7, learning_rate=1e-05, batch_size=32, cell_type=LSTM\n",
      "Epoch 1/100\n",
      "6773/6773 [==============================] - 97s 14ms/step - loss: 1.0779 - mae: 0.8633 - val_loss: 1.0131 - val_mae: 0.8637 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "6773/6773 [==============================] - 94s 14ms/step - loss: 1.0509 - mae: 0.8532 - val_loss: 0.9501 - val_mae: 0.8381 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "6773/6773 [==============================] - 93s 14ms/step - loss: 1.0320 - mae: 0.8458 - val_loss: 0.9116 - val_mae: 0.8212 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "6773/6773 [==============================] - 93s 14ms/step - loss: 1.0114 - mae: 0.8381 - val_loss: 0.8863 - val_mae: 0.8082 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "6773/6773 [==============================] - 93s 14ms/step - loss: 0.9822 - mae: 0.8265 - val_loss: 0.8698 - val_mae: 0.7932 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "6773/6773 [==============================] - 93s 14ms/step - loss: 0.9485 - mae: 0.8125 - val_loss: 0.8510 - val_mae: 0.7774 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "6773/6773 [==============================] - 92s 14ms/step - loss: 0.9140 - mae: 0.7970 - val_loss: 0.8457 - val_mae: 0.7721 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "6773/6773 [==============================] - 92s 14ms/step - loss: 0.8775 - mae: 0.7785 - val_loss: 0.8599 - val_mae: 0.7751 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "6769/6773 [============================>.] - ETA: 0s - loss: 0.8411 - mae: 0.7576\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "6773/6773 [==============================] - 92s 14ms/step - loss: 0.8408 - mae: 0.7575 - val_loss: 0.8931 - val_mae: 0.7892 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "6773/6773 [==============================] - 93s 14ms/step - loss: 0.8138 - mae: 0.7414 - val_loss: 0.9151 - val_mae: 0.8012 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "6772/6773 [============================>.] - ETA: 0s - loss: 0.7977 - mae: 0.7309\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "6773/6773 [==============================] - 93s 14ms/step - loss: 0.7977 - mae: 0.7309 - val_loss: 0.9520 - val_mae: 0.8178 - lr: 5.0000e-06\n",
      "Epoch 12/100\n",
      "6773/6773 [==============================] - 93s 14ms/step - loss: 0.7836 - mae: 0.7218 - val_loss: 0.9716 - val_mae: 0.8253 - lr: 2.5000e-06\n",
      "Epoch 13/100\n",
      "6771/6773 [============================>.] - ETA: 0s - loss: 0.7758 - mae: 0.7167\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "6773/6773 [==============================] - 93s 14ms/step - loss: 0.7757 - mae: 0.7166 - val_loss: 0.9911 - val_mae: 0.8324 - lr: 2.5000e-06\n",
      "Epoch 14/100\n",
      "6773/6773 [==============================] - 94s 14ms/step - loss: 0.7684 - mae: 0.7120 - val_loss: 1.0006 - val_mae: 0.8359 - lr: 1.2500e-06\n",
      "Epoch 15/100\n",
      "6773/6773 [==============================] - ETA: 0s - loss: 0.7639 - mae: 0.7088\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "6773/6773 [==============================] - 93s 14ms/step - loss: 0.7639 - mae: 0.7088 - val_loss: 1.0106 - val_mae: 0.8394 - lr: 1.2500e-06\n",
      "Epoch 16/100\n",
      "6773/6773 [==============================] - 93s 14ms/step - loss: 0.7613 - mae: 0.7074 - val_loss: 1.0186 - val_mae: 0.8423 - lr: 1.0000e-06\n",
      "Epoch 17/100\n",
      "6773/6773 [==============================] - 93s 14ms/step - loss: 0.7583 - mae: 0.7050 - val_loss: 1.0268 - val_mae: 0.8452 - lr: 1.0000e-06\n",
      "  -> best_val_mse (history): 0.845655 encontrado en la permutaci√≥n: 7 , best_val_mse (evaluated): 0.845655, best_train_mse (evaluated): 0.790576, best_val_mae: 0.772081, epochs: 17, total_time: 1584.64s\n",
      "Entrenando con: latent_dim=16, dropout=0.7, learning_rate=1e-05, batch_size=64, cell_type=LSTM\n",
      "Epoch 1/100\n",
      "3387/3387 [==============================] - 51s 14ms/step - loss: 1.1497 - mae: 0.8868 - val_loss: 0.9994 - val_mae: 0.8039 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 1.1120 - mae: 0.8737 - val_loss: 0.9507 - val_mae: 0.7913 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "3387/3387 [==============================] - 48s 14ms/step - loss: 1.0875 - mae: 0.8649 - val_loss: 0.9156 - val_mae: 0.7799 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 1.0720 - mae: 0.8594 - val_loss: 0.8922 - val_mae: 0.7712 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 1.0581 - mae: 0.8544 - val_loss: 0.8787 - val_mae: 0.7653 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 1.0473 - mae: 0.8501 - val_loss: 0.8685 - val_mae: 0.7602 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 1.0358 - mae: 0.8457 - val_loss: 0.8644 - val_mae: 0.7576 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 1.0245 - mae: 0.8409 - val_loss: 0.8649 - val_mae: 0.7572 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "3386/3387 [============================>.] - ETA: 0s - loss: 1.0132 - mae: 0.8366\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 1.0132 - mae: 0.8366 - val_loss: 0.8662 - val_mae: 0.7579 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 1.0033 - mae: 0.8327 - val_loss: 0.8707 - val_mae: 0.7598 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "3386/3387 [============================>.] - ETA: 0s - loss: 0.9978 - mae: 0.8301\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 0.9977 - mae: 0.8301 - val_loss: 0.8734 - val_mae: 0.7619 - lr: 5.0000e-06\n",
      "Epoch 12/100\n",
      "3387/3387 [==============================] - 48s 14ms/step - loss: 0.9930 - mae: 0.8283 - val_loss: 0.8749 - val_mae: 0.7628 - lr: 2.5000e-06\n",
      "Epoch 13/100\n",
      "3384/3387 [============================>.] - ETA: 0s - loss: 0.9891 - mae: 0.8264\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 0.9887 - mae: 0.8263 - val_loss: 0.8763 - val_mae: 0.7640 - lr: 2.5000e-06\n",
      "Epoch 14/100\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 0.9860 - mae: 0.8256 - val_loss: 0.8748 - val_mae: 0.7634 - lr: 1.2500e-06\n",
      "Epoch 15/100\n",
      "3387/3387 [==============================] - ETA: 0s - loss: 0.9847 - mae: 0.8247\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 0.9847 - mae: 0.8247 - val_loss: 0.8766 - val_mae: 0.7644 - lr: 1.2500e-06\n",
      "Epoch 16/100\n",
      "3387/3387 [==============================] - 47s 14ms/step - loss: 0.9837 - mae: 0.8243 - val_loss: 0.8765 - val_mae: 0.7645 - lr: 1.0000e-06\n",
      "Epoch 17/100\n",
      "3387/3387 [==============================] - 48s 14ms/step - loss: 0.9820 - mae: 0.8236 - val_loss: 0.8773 - val_mae: 0.7648 - lr: 1.0000e-06\n",
      "  -> best_val_mse (history): 0.864385 encontrado en la permutaci√≥n: 7 , best_val_mse (evaluated): 0.864326, best_train_mse (evaluated): 1.027662, best_val_mae: 0.757154, epochs: 17, total_time: 806.85s\n",
      "Entrenando con: latent_dim=16, dropout=0.8, learning_rate=0.0001, batch_size=32, cell_type=LSTM\n",
      "Epoch 1/100\n",
      "6773/6773 [==============================] - 98s 14ms/step - loss: 0.9257 - mae: 0.7803 - val_loss: 1.2874 - val_mae: 0.9235 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "6773/6773 [==============================] - 93s 14ms/step - loss: 0.7882 - mae: 0.7055 - val_loss: 1.2922 - val_mae: 0.9544 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "6773/6773 [==============================] - 91s 13ms/step - loss: 0.6695 - mae: 0.6345 - val_loss: 1.0055 - val_mae: 0.7954 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "6773/6773 [==============================] - 91s 13ms/step - loss: 0.5753 - mae: 0.5811 - val_loss: 0.9045 - val_mae: 0.7582 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "6773/6773 [==============================] - 92s 14ms/step - loss: 0.5137 - mae: 0.5471 - val_loss: 0.8352 - val_mae: 0.7179 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "6773/6773 [==============================] - 92s 14ms/step - loss: 0.4623 - mae: 0.5152 - val_loss: 0.7963 - val_mae: 0.7110 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "6773/6773 [==============================] - 92s 14ms/step - loss: 0.4172 - mae: 0.4849 - val_loss: 0.6912 - val_mae: 0.6315 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "6773/6773 [==============================] - 93s 14ms/step - loss: 0.3740 - mae: 0.4566 - val_loss: 0.6636 - val_mae: 0.6199 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "6773/6773 [==============================] - 92s 14ms/step - loss: 0.3405 - mae: 0.4322 - val_loss: 0.6760 - val_mae: 0.6401 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "6773/6773 [==============================] - ETA: 0s - loss: 0.3084 - mae: 0.4084\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "6773/6773 [==============================] - 92s 14ms/step - loss: 0.3084 - mae: 0.4084 - val_loss: 0.6866 - val_mae: 0.6540 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "6773/6773 [==============================] - 92s 14ms/step - loss: 0.3071 - mae: 0.4098 - val_loss: 0.6777 - val_mae: 0.6448 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "6773/6773 [==============================] - ETA: 0s - loss: 0.2912 - mae: 0.3963\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "6773/6773 [==============================] - 92s 14ms/step - loss: 0.2912 - mae: 0.3963 - val_loss: 0.6820 - val_mae: 0.6463 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "6773/6773 [==============================] - 92s 14ms/step - loss: 0.2991 - mae: 0.4027 - val_loss: 0.6890 - val_mae: 0.6502 - lr: 2.5000e-05\n",
      "Epoch 14/100\n",
      "6773/6773 [==============================] - ETA: 0s - loss: 0.2929 - mae: 0.3967\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "6773/6773 [==============================] - 92s 14ms/step - loss: 0.2929 - mae: 0.3967 - val_loss: 0.7072 - val_mae: 0.6571 - lr: 2.5000e-05\n",
      "Epoch 15/100\n",
      "6773/6773 [==============================] - 93s 14ms/step - loss: 0.3010 - mae: 0.4020 - val_loss: 0.7296 - val_mae: 0.6654 - lr: 1.2500e-05\n",
      "Epoch 16/100\n",
      "6769/6773 [============================>.] - ETA: 0s - loss: 0.2938 - mae: 0.3961\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "6773/6773 [==============================] - 94s 14ms/step - loss: 0.2936 - mae: 0.3960 - val_loss: 0.7371 - val_mae: 0.6681 - lr: 1.2500e-05\n",
      "Epoch 17/100\n",
      "6773/6773 [==============================] - 94s 14ms/step - loss: 0.2982 - mae: 0.3980 - val_loss: 0.7485 - val_mae: 0.6713 - lr: 6.2500e-06\n",
      "Epoch 18/100\n",
      "6771/6773 [============================>.] - ETA: 0s - loss: 0.2927 - mae: 0.3940\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "6773/6773 [==============================] - 93s 14ms/step - loss: 0.2926 - mae: 0.3940 - val_loss: 0.7517 - val_mae: 0.6716 - lr: 6.2500e-06\n",
      "  -> best_val_mse (history): 0.663630 encontrado en la permutaci√≥n: 8 , best_val_mse (evaluated): 0.663630, best_train_mse (evaluated): 0.929634, best_val_mae: 0.619882, epochs: 18, total_time: 1668.56s\n",
      "Entrenando con: latent_dim=16, dropout=0.8, learning_rate=0.0001, batch_size=64, cell_type=LSTM\n",
      "Epoch 1/100\n",
      "3387/3387 [==============================] - 51s 14ms/step - loss: 1.0457 - mae: 0.8490 - val_loss: 0.8319 - val_mae: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "3387/3387 [==============================] - 48s 14ms/step - loss: 0.9289 - mae: 0.7911 - val_loss: 1.0948 - val_mae: 0.8666 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "3384/3387 [============================>.] - ETA: 0s - loss: 0.8114 - mae: 0.7279\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "3387/3387 [==============================] - 48s 14ms/step - loss: 0.8110 - mae: 0.7277 - val_loss: 1.4824 - val_mae: 1.0235 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "3387/3387 [==============================] - 48s 14ms/step - loss: 0.7247 - mae: 0.6762 - val_loss: 1.6035 - val_mae: 1.0727 - lr: 5.0000e-05\n",
      "Epoch 5/100\n",
      "3386/3387 [============================>.] - ETA: 0s - loss: 0.6801 - mae: 0.6487\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "3387/3387 [==============================] - 48s 14ms/step - loss: 0.6800 - mae: 0.6486 - val_loss: 1.6215 - val_mae: 1.0770 - lr: 5.0000e-05\n",
      "Epoch 6/100\n",
      " 964/3387 [=======>......................] - ETA: 32s - loss: 0.6437 - mae: 0.6083"
     ]
    }
   ],
   "source": [
    "# Calculo estas 2 variables que ser√°n fijas\n",
    "num_features = len(feature_cols)\n",
    "num_targets  = len(target_cols)\n",
    "\n",
    "for latent_dim_val, dropout_val, lr_val, batch_size_val, cell_type_val in itertools.product(\n",
    "        grid_params[\"latent_dim\"],\n",
    "        grid_params[\"dropout\"],\n",
    "        grid_params[\"learning_rate\"],\n",
    "        grid_params[\"batch_size\"],\n",
    "        grid_params[\"cell_type\"]):\n",
    "\n",
    "    print(f\"Entrenando con: latent_dim={latent_dim_val}, dropout={dropout_val}, \"\n",
    "          f\"learning_rate={lr_val}, batch_size={batch_size_val}, cell_type={cell_type_val}\")\n",
    "    \n",
    "    # Construir el modelo con la combinaci√≥n actual\n",
    "    model = build_rnn_direct(num_features, num_targets, WINDOW_SIZE,\n",
    "                             latent_dim=latent_dim_val,\n",
    "                             dropout=dropout_val,\n",
    "                             learning_rate=lr_val,\n",
    "                             cell_type=cell_type_val)\n",
    "    \n",
    "    # Callbacks:\n",
    "    # - EarlyStopping: para detener el entrenamiento si no mejora el val_loss.\n",
    "    # - ReduceLROnPlateau: para ajustar la tasa de aprendizaje si el val_loss se estanca.\n",
    "    # - TimeHistory: para medir el tiempo por √©poca.\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=0)\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6, verbose=1)\n",
    "    time_callback = TimeHistory()\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, Y_train,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        epochs=100,\n",
    "        shuffle=False, # Se procesa en orden, sin aleatorizaci√≥n\n",
    "        batch_size=batch_size_val,\n",
    "        callbacks=[early_stopping, lr_scheduler, time_callback],\n",
    "        verbose=1  # Poner 1 para ver el progreso\n",
    "    )\n",
    "    total_training_time = time.time() - start_time\n",
    "    epoch_times = time_callback.times\n",
    "    epochs_ran = len(epoch_times)\n",
    "\n",
    "    # Obtener el menor valor de val_loss (MSE) del history y su √≠ndice\n",
    "    best_val_mse = min(history.history[\"val_loss\"])\n",
    "    best_epoch_idx = np.argmin(history.history[\"val_loss\"])\n",
    "    \n",
    "    # Opci√≥n: evaluar el modelo (con los mejores pesos restaurados) en los conjuntos de train y val.\n",
    "    train_results = model.evaluate(X_train, Y_train, verbose=0)\n",
    "    val_results   = model.evaluate(X_val, Y_val, verbose=0)\n",
    "    # Suponiendo que el modelo se compil√≥ con metrics=['mae', 'mse'], los √≠ndices ser√°n:\n",
    "    # 0: loss (mse), 1: mae, 2: mse\n",
    "    best_train_mse_eval = train_results[0]\n",
    "    best_val_mse_eval   = val_results[0]\n",
    "    \n",
    "    # Tambi√©n obtener el m√≠nimo valor de val_mae (por si interesa)\n",
    "    best_val_mae = min(history.history[\"val_mae\"])\n",
    "    \n",
    "    # Guardamos el history completo para poder graficar las curvas de aprendizaje despu√©s.\n",
    "    learning_curve = history.history\n",
    "\n",
    "    # Guardar los resultados en el diccionario\n",
    "    results_list.append({\n",
    "        \"latent_dim\": latent_dim_val,\n",
    "        \"dropout\": dropout_val,\n",
    "        \"learning_rate\": lr_val,\n",
    "        \"batch_size\": batch_size_val,\n",
    "        \"cell_type\": cell_type_val,\n",
    "        \"best_val_mse\": best_val_mse,  # extra√≠do del history\n",
    "        \"best_val_mse_epoch_idx\": best_epoch_idx, # Permutaci√≥n donde se encontr√≥ el best_val_mse\n",
    "        \"best_train_mse_eval\": best_train_mse_eval,  # evaluado sobre el set de entrenamiento\n",
    "        \"best_val_mse_eval\": best_val_mse_eval,        # evaluado sobre el set de validaci√≥n\n",
    "        \"best_val_mae\": best_val_mae,\n",
    "        \"epochs_ran\": epochs_ran,\n",
    "        \"epoch_times\": epoch_times,\n",
    "        \"total_training_time\": total_training_time,\n",
    "        \"learning_curve\": learning_curve  # Este diccionario se usar√° para graficar las curvas de aprendizaje\n",
    "    })\n",
    "    \n",
    "    print(f\"  -> best_val_mse (history): {best_val_mse:.6f} encontrado en la permutaci√≥n: {best_epoch_idx+1} , \"\n",
    "          f\"best_val_mse (evaluated): {best_val_mse_eval:.6f}, \"\n",
    "          f\"best_train_mse (evaluated): {best_train_mse_eval:.6f}, \"\n",
    "          f\"best_val_mae: {best_val_mae:.6f}, \"\n",
    "          f\"epochs: {epochs_ran}, total_time: {total_training_time:.2f}s\")\n",
    "\n",
    "# Crear un DataFrame con los resultados del grid search\n",
    "df_results = pd.DataFrame(results_list)\n",
    "print(\"\\nGrid Search Results:\")\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3efce41-3dda-4f8e-aae0-736a6560e676",
   "metadata": {},
   "source": [
    "# Seleccionar los mejores hiperpar√°metros (seg√∫n el menor MSE en validaci√≥n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf36eb6-83d5-4a6a-b7c2-5d55ab479817",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_idx = df_results['best_val_mse'].idxmin()\n",
    "best_params = df_results.loc[best_idx]\n",
    "print(\"\\nBest Hyperparameters Found:\")\n",
    "print(best_params)\n",
    "\n",
    "# Reconstruir el mejor modelo con los hiperpar√°metros √≥ptimos\n",
    "best_model = build_rnn_direct(num_features, num_targets, WINDOW_SIZE,\n",
    "                              latent_dim=int(best_params['latent_dim']),\n",
    "                              dropout=best_params['dropout'],\n",
    "                              learning_rate=best_params['learning_rate'],\n",
    "                              cell_type=best_params['cell_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec00f38-8779-4886-873b-ef69fdd497fb",
   "metadata": {},
   "source": [
    "# Entrenamiento final del mejor modelo usando train y validaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48044e67-eaa5-4237-99ff-e1a4a6c0bd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "final_checkpoint = ModelCheckpoint(MEJOR_MODELO, monitor='val_loss', save_best_only=True)\n",
    "final_lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6, verbose=1)\n",
    "\n",
    "history_final = best_model.fit(\n",
    "    X_train, Y_train,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    epochs=50,\n",
    "    shuffle=False,\n",
    "    batch_size=int(best_params['batch_size']),\n",
    "    callbacks=[final_early_stopping, final_checkpoint, final_lr_scheduler],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Cargar el mejor modelo guardado\n",
    "best_model = models.load_model(MEJOR_MODELO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d69228-4283-4f68-8d1a-10d07fa2434e",
   "metadata": {},
   "source": [
    "# Predicci√≥n sobre el conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf3dac8-fd79-401e-852f-43ad6e2f371e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = best_model.predict(X_test)\n",
    "print(\"\\nPredicciones en TEST completadas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa82045-a28f-4bd7-a7ea-c3e2775e063b",
   "metadata": {},
   "source": [
    "# Guardar resultados y predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84e35a2-2a7d-4069-a2ef-5aa5c3246144",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    \"df_results\": df_results,\n",
    "    \"predictions_test\": Y_pred,\n",
    "    \"windows_size\": WINDOW_SIZE,\n",
    "    \"offset\": OFFSET\n",
    "}\n",
    "\n",
    "# Guardar en un solo archivo\n",
    "joblib.dump(data_dict, FIC_SALIDA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3252b0-826f-459f-aac1-e8d5facdcbc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
