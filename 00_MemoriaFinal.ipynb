{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1856cf1c-2274-4eb7-ab79-e448d4ec9eb6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<!-- Portada -->\n",
    "<div style=\"display: flex; justify-content: center; align-items: center; height: 100vh; font-family: Arial, sans-serif; background-color: #f4f4f4; text-align: center;\">\n",
    "    <div style=\"background: white; padding: 50px; border-radius: 10px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2); width: 70%; max-width: 800px;\">\n",
    "        <h1 style=\"font-size: 32px; margin-bottom: 20px; color: #333;\">Predicción de color LAB para máquinas industriales</h1>\n",
    "        <h2 style=\"color: #555;\">Máster en Inteligencia Artificial</h2>\n",
    "        <h3 style=\"color: #555;\">Universidad Complutense de Madrid</h3>\n",
    "        <h4 style=\"color: #555;\">Fecha: <script>document.write(new Date().toLocaleDateString());</script></h4>\n",
    "        <h4 style=\"color: #555;\">Alumno: <strong>Jaume Poch Blanch</strong></h4>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "# **Índice**  \n",
    "\n",
    "## 📌 [1. Introducción](#introduccion)  \n",
    "   - [Objetivo del proyecto](#objetivodelproyecto)  \n",
    "   - [Contexto industrial](#contextoindustrial)  \n",
    "   - [Problema actual en la impresión sobre plástico](#problemaactual)  \n",
    "   - [Propuesta de valor](#propuestadevalor)  \n",
    "\n",
    "## 📌 [2. Estudio del problema con el equipo](#estudiodelproblemaconelequipo)  \n",
    "\n",
    "## 📌 [3. Datos](#datos)  \n",
    "   - [Obtención de datos](#obtenciondedatos)  \n",
    "   - [Representación gráfica de la simulación](#representaciongraficadelasimulacion)  \n",
    "\n",
    "## 📌 [4. Procesamiento y Transformación de Datos](#procesamientoytransformaciondedatos)  \n",
    "   - [Enriquecimiento de datos](#enriquecimientodedatos)  \n",
    "   - [Eliminación de filas no relevantes](#eliminaciondefilasnorelevantes)  \n",
    "\n",
    "## 📌 [5. Análisis Exploratorio de Datos (EDA)](#analisisexploratoriodedatoseda)  \n",
    "   - [Eliminar y adecuar datos](#eliminaciondevariablesinnecesarias)  \n",
    "   - [Transformaciones de datos](#transformacionesdedatos)  \n",
    "   - [Matriz de correlación](#matrizdecorrelacion)\n",
    "   - [División en conjuntos de Train/Test/Validación](#divisionentrenuestrosconjuntos)  \n",
    "\n",
    "## 📌 [6. Modelado](#modelado)  \n",
    "   - [Definición del Modelado y Selección de Métricas](#definiciondelmodelado)  \n",
    "     - [Métricas de Evaluación](#metricasdeevaluacion)  \n",
    "     - [Consideraciones sobre la Arquitectura](#consideracionessobrelasarquitecturas)  \n",
    "     - [Comparación de Enfoques](#comparacionrnntransformers)  \n",
    "   - [Configuraciones y Parámetros Globales para todos los modelos implementados](#configuracioninicial)  \n",
    "     - [Desfase y Tamaño de Ventana](#tamanoventana)  \n",
    "     - [Reproducibilidad](#reproducibilidad)  \n",
    "     - [Optimizaciones](#optimizaciones)  \n",
    "   - [Implementación de Modelos elegidos](#implementaciondemodelos)  \n",
    "     - [Modelos Basados en RNN (LSTM y GRU)](#rnnbasadosmodelos)  \n",
    "       - [Decisiones Clave en la Arquitectura](#decisionesclavegrulstm)  \n",
    "       - [Optimización y Ajuste de Hiperparámetros](#optimizacionhiperparametros)  \n",
    "     - [Modelos Basados en Transformers](#transformersbasadosmodelos)\n",
    "       - [Consideraciones sobre la Arquitectura del Modelo](#consideracionessobrelasarquitecturas)  \n",
    "       - [Optimización y Ajuste de Hiperparámetros](#optimizacionhiperparametros_transformers)\n",
    "         \n",
    "## 📌 [7. Evaluación y Comparación de Modelos](#evaluacionycomparaciondemodelos)  \n",
    "   - [Observaciones Globales en Modelos GRU, LSTM y Transformers](#observacionesglobalesgrulstmtransformers)  \n",
    "   - [Evaluación GRU](#evaluaciongru)  \n",
    "     - [Resultados de los experimentos GRU](#resultadosexperimentogru)\n",
    "     - [Conclusiones GRU](#conclusionesgru)\n",
    "   - [Evaluación LSTM](#evaluacionlstm)  \n",
    "     - [Resultados de los experimentos LSTM](#resultadosexperimentolstm)\n",
    "     - [Conclusiones LSTM](#conclusioneslstm)\n",
    "   - [Evaluación Transformers](#evaluaciontransformers)  \n",
    "     - [Conclusiones Transformers](#conclusionestransformers)\n",
    "   - [El mejor modelo](#elmejormodelo)  \n",
    "\n",
    "## 📌 [8. Conclusiones](#conclusionesymejorasfuturas)  \n",
    "   - [Conclusiones Principales del estudio actual](#conclusionesprincipalesestudioactual)  \n",
    "   - [Mejoras para las siguientes iteraciones](#mejorassiguientesiteraciones)  \n",
    "   - [Lecciones Aprendidas](#leccionesaprendidas)  \n",
    "   - [Informe Ejecutivo](#informeejecutivo)  \n",
    "\n",
    "## 📌 [9. Bibliografía y Recursos](#bibliografiayrecursos)  \n",
    "\n",
    "## 📌 [10. Anexos](#anexos)  \n",
    "\n",
    "---\n",
    "\n",
    "<!-- Sección 1: Introducción -->\n",
    "<a name=\"introduccion\"></a>\n",
    "# **1. Introducción**  \n",
    "\n",
    "<a name=\"objetivodelproyecto\"></a>\n",
    "## 📌 **Objetivo del proyecto**  \n",
    "\n",
    "Este proyecto tiene como finalidad desarrollar un modelo de predicción de color para máquinas industriales de impresión sobre plástico.\n",
    "\n",
    "<a name=\"contextoindustrial\"></a>\n",
    "## 📌 **Contexto industrial**  \n",
    "\n",
    "La empresa para la que se desarrolla este proyecto se especializa en la venta de componentes para estas máquinas, en particular cámaras que capturan diferentes partes de la impresión y las transforman en valores del espacio de color **CIELAB**. Estos valores se comparan con el color requerido por el cliente y, si exceden ciertos umbrales de tolerancia, generan una alarma para ajustar el color y mantenerlo dentro de los parámetros aceptables.\n",
    "\n",
    "Las mediciones de color se almacenan en un archivo XML bajo el estándar industrial **ISO 17972-1:2015**.\n",
    "\n",
    "<a name=\"problemaactual\"></a>\n",
    "## 📌 **Problema actual en la impresión sobre plástico**  \n",
    "\n",
    "Los principales desafíos que enfrenta el sistema actual son:\n",
    "\n",
    "- **Ubicación de las cámaras:** Las máquinas industriales poseen diversas configuraciones, lo que implica que las cámaras de visión se sitúan en diferentes posiciones y distancias respecto a los inyectores de color.\n",
    "- **Sistema reactivo en lugar de predictivo:** Actualmente, los ajustes de color solo ocurren tras detectar una desviación, lo que genera desperdicio de material.\n",
    "- **Reducción de la merma:** Los errores de impresión generan desechos de plástico innecesarios.\n",
    "- **Pérdida de productividad:** Las intervenciones manuales para reajustar los colores interrumpen la producción.\n",
    "\n",
    "<a name=\"propuestadevalor\"></a>\n",
    "## 📌 **Propuesta de valor**  \n",
    "\n",
    "Para abordar estos problemas, se busca desarrollar un modelo que pueda **predecir los valores LAB con antelación**, permitiendo intervenir antes de que el color se salga de los umbrales permitidos. Esto proporcionaría varios beneficios:\n",
    "\n",
    "- **Reducción de la merma:** Al anticipar los fallos, se minimizaría la cantidad de material desechado.\n",
    "- **Mayor eficiencia y sostenibilidad:** Se reduciría el impacto ambiental al disminuir el desperdicio de plástico.\n",
    "- **Automatización del ajuste de color:** En caso de una predicción precisa, se podría implementar un sistema que ajuste los inyectores automáticamente, eliminando la necesidad de intervención humana y mejorando la productividad.\n",
    "\n",
    "---\n",
    "\n",
    "<!-- Sección 2: Estudio del problema con el equipo -->\n",
    "<a name=\"estudiodelproblemaconelequipo\"></a>\n",
    "# **2. Estudio del problema con el equipo**\n",
    "\n",
    "Tras un proceso intensivo de reuniones y consultas con los expertos de la empresa, se han identificado y analizado los factores clave que influyen en la variación del color durante la impresión sobre plástico. Estos hallazgos permiten definir, por un lado, los retos que se deben abordar en el desarrollo del modelo predictivo y, por otro, las conclusiones que fundamentan el enfoque propuesto. A continuación, se resumen los puntos más relevantes:\n",
    "\n",
    "- **Velocidad de la máquina:**\n",
    "  - *Parada:* No hay producción ni movimiento, lo que permite evaluar el comportamiento del sistema en inactividad.\n",
    "  - *Puesta a punto:* Durante la fase de ajuste de parámetros y pruebas de impresión, con velocidades entre 10 y 50 m/min.\n",
    "  - *Velocidad normal:* Operación en condiciones de producción estable (300-350 m/min), donde se espera obtener resultados consistentes.\n",
    "  - *Velocidad máxima:* En escenarios de alta producción (alrededor de 500 m/min), donde la precisión puede verse comprometida.\n",
    "\n",
    "- **Medición del color LAB:**  \n",
    "  Se utilizan cámaras que capturan los valores del espacio **CIELAB** conforme al estándar definido. El equipo nos proporciona un fichero tipo en formato XML, que recoge las lecturas de los valores por el sistema de visión, permitiendo así una integración precisa de los datos en el modelo.\n",
    "\n",
    "- **Condiciones ambientales (Humedad y Temperatura):**  \n",
    "  Aunque se reconocen como variables potencialmente influyentes, se decidió no incorporarlas en el modelo debido a la ausencia de sensores adecuados para su medición precisa.\n",
    "\n",
    "- **Patrones de impresión:**  \n",
    "  La diversidad de diseños y patrones impresos por cada cliente se refleja en las variaciones de los valores LAB, lo que añade complejidad al análisis pero también ofrece información valiosa para la predicción.\n",
    "\n",
    "- **Tipo de plástico:**  \n",
    "  A pesar de su impacto en el proceso de impresión, se ha optado por descartar este factor en el modelado sintético, debido a la alta complejidad que implica su correcta simulación.\n",
    "\n",
    "---\n",
    "\n",
    "<!-- Sección 3: Datos -->\n",
    "<a name=\"datos\"></a>\n",
    "# **3. Datos**\n",
    "\n",
    "> Para más detalles específicos sobre esta fase de generación de datos ver los notebooks [**02_generador_datos_sinteticos.ipynb** y **01_DatosMeteorologicos.ipynb**](#anexos).\n",
    "\n",
    "<a name=\"obtenciondedatos\"></a>\n",
    "## 📌 **Obtención de datos**\n",
    "\n",
    "Para lo obtención de datos:\n",
    "\n",
    "| **Proceso**                          | **Descripción** | **Referencia** |\n",
    "|--------------------------------------|---------------|---------------|\n",
    "| **Incorporación de datos meteorológicos** | Datos de [AEMET](https://www.aemet.es/). | **01_DatosMeteorologicos.ipynb** ([Anexo](#anexos)) |\n",
    "| **Generación de datos sintéticos:** | | **02_generador_datos_sinteticos.ipynb** [(Anexo)](#anexos) |\n",
    "| - **Discretizar el tiempo** | División del día en \"n\" intervalos. | Apartado **Discretizador de tiempo** |\n",
    "| - **Añadir velocidad** | Considera aceleraciones, estados y ruido. | Apartado **Velocidad de la máquina** |\n",
    "| - **Añadir color LAB** | Generación del color según parámetros. | Apartado **Cálculo de color LAB** |\n",
    "\n",
    "<a name=\"representaciongraficadelasimulacion\"></a>\n",
    "## **Representación gráfica de la simulación**\n",
    "\n",
    "La representación gráfica de los [datos sintéticos con los que trabajaré se puede encontrar aquí](https://github.com/laperl/MasterIA/blob/main/Resultados/RepresentacionDatosSinteticos.jpg).\n",
    "\n",
    "Cada ejecución del notebook **\"02_generador_datos_sinteticos.ipynb\"** genera gráficos interactivos (utilizando la librería *plotly*) que ilustran la evolución de la velocidad y del color a lo largo del tiempo. Estos gráficos, que se abren en una ventana separada para permitir zoom y exploración detallada, muestran la variabilidad y el comportamiento de la máquina, simulando diferentes escenarios de operación.\n",
    "\n",
    "> **NOTA IMPORTANTE:** Para poder obtener los mismos resultados, se han anexado los ficheros generados en una ejecución en los archivos adjuntos (\"02_datos_limpios - BCK_ENTREGA.pkl\" y \"02_datos_limpios_sin_parada - BCK_ENTREGA.pkl\"). De esta forma, se puede reproducir el experimento, ya que al volver a ejecutar el notebook, los datos generados serán diferentes.\n",
    "\n",
    "---\n",
    "\n",
    "<!-- Sección 4: Procesamiento y Transformación de Datos -->\n",
    "<a name=\"procesamientoytransformaciondedatos\"></a>\n",
    "# **4. Procesamiento y Transformación de Datos**\n",
    "\n",
    "<a name=\"enriquecimientodedatos\"></a>\n",
    "## 📌 **Enriquecimiento de datos**\n",
    "\n",
    "Inicialmente, el dataset contiene las siguientes columnas:\n",
    "\n",
    "| **Variable**       | **Descripción**                                                                                                   |\n",
    "|--------------------|-------------------------------------------------------------------------------------------------------------------|\n",
    "| **Índice**         | Datetime con subdivisiones del día. Cada fila representa una medición en un instante determinado.                 |\n",
    "| **Color LAB**      | Tres columnas que contienen los valores medidos en el espacio de color LAB.                                        |\n",
    "| **Color LAB base** | Tres columnas con el color requerido por el cliente (valor de referencia).                                         |\n",
    "| **Velocidad**      | Indica el estado de la máquina: \"parada\", \"puesta\", \"normal\" o \"alta\". En estado \"parada\", el valor es nulo.         |\n",
    "\n",
    "Dado que los modelos iniciales basados únicamente en estas variables mostraron resultados poco satisfactorios, se procedió a enriquecer el dataset mediante las siguientes transformaciones:\n",
    "\n",
    "| **Proceso**                          | **Descripción** | **Referencia** |\n",
    "|--------------------------------------|---------------|---------------|\n",
    "| **Cálculo del indicador Δ𝐸** | Diferencia entre el color medido y el color base usando la fórmula **CIE76**. No se integró en el modelo final. | - |\n",
    "| **Identificación del patrón de impresión** | Se añade un identificador único para cada patrón de impresión. | Apartado **Enriquecimiento de los datos** ([**02_generador_datos_sinteticos.ipynb** anexo](#anexos)) |\n",
    "| **Transformación del momento del día** | Se aplica seno y coseno a la hora para capturar periodicidad. | Apartado **Enriquecimiento de los datos** ([**02_generador_datos_sinteticos.ipynb** anexo](#anexos)) |\n",
    "| **Duración de la parada anterior** | Se calcula y guarda la duración de cada bloque de paradas antes de eliminarlas. | Apartado **Enriquecimiento de los datos** ([**02_generador_datos_sinteticos.ipynb** anexo](#anexos)) |\n",
    "| **Tiempo acumulado en cada estado** | Contador de tiempo continuo en cada estado antes de un cambio. | Apartado **Enriquecimiento de los datos** ([**02_generador_datos_sinteticos.ipynb** anexo](#anexos)) |\n",
    "\n",
    "> **NOTA IMPORTANTE:** Para poder obtener los mismos resultados, se han añadido los datos generados de base en el repositorio. De esta forma, se puede reproducir el experimento, ya que al volver a ejecutar el notebook, los datos generados serán diferentes.\n",
    "\n",
    "<a name=\"eliminaciondefilasnorelevantes\"></a>\n",
    "## 📌 **Eliminación de filas no relevantes**\n",
    "\n",
    "Una vez enriquecido el dataset, se procede a su depuración para optimizar la calidad de las predicciones:\n",
    "\n",
    "- **Supresión de filas con estado \"parada\":**  \n",
    "  Debido a que en los periodos en que la máquina está parada no se generan valores de color relevantes, se eliminan estas filas. Sin embargo, para no perder la información acerca de los paros, se ha añadido la columna **\"duracion_parada_anterior\"** en la primera fila posterior a cada bloque de paradas.\n",
    "\n",
    "- **Incorporar la secuencia temporal (seq_time):**  \n",
    "  La eliminación de las filas con estado \"parada\" provoca saltos en la secuencia temporal. Para solucionar este problema y mantener la continuidad necesaria para modelos secuenciales (como las RNN), se introduce la columna **\"seq_time\"**, que reordena y numeriza de forma consecutiva las filas restantes.\n",
    "\n",
    "Este proceso de enriquecimiento y depuración de datos ha permitido transformar el dataset inicial en una estructura mucho más informativa y adecuada para el modelado predictivo, preservando tanto la secuencia temporal como la información relevante sobre la operación de la máquina. Los detalles técnicos y la implementación completa de estos pasos se pueden consultar en los notebooks anexos mencionados. \n",
    "\n",
    "---\n",
    "\n",
    "<!-- Sección 5: Análisis Exploratorio de Datos (EDA) -->\n",
    "<a name=\"analisisexploratoriodedatoseda\"></a>\n",
    "# **5. Análisis Exploratorio de Datos (EDA) y transformaciones**\n",
    "\n",
    "> Para más detalles específicos sobre esta fase de transformación y análisis se encuentran en el notebook [**03_AnalisisDeDatos.ipynb**](#anexos).\n",
    "\n",
    "Después de los pasos previos de generación de datos, el dataset cuenta con las siguientes columnas:\n",
    "\n",
    "| **Categoría**              | **Variables** |\n",
    "|---------------------------|----------------------------------------------------------------|\n",
    "| **Datos Meteorológicos**  | `tmin`, `tmed`, `tmax`, `horatmin`, `horatmax`, `hrMin`, `hrMedia`, `hrMax`, `horaHrMin`, `horaHrMax` |\n",
    "| **Datos Operativos y de Color** | `estado`, `velocidad`, `L`, `L_base`, `A`, `A_base`, `B`, `B_base`, `Delta_E` |\n",
    "| **Datos Enriquecidos**     | `patron_id`, `hour_sin`, `hour_cos`, `duracion_parada_anterior`, `tiempo_en_estado`, `seq_time` |\n",
    "\n",
    "\n",
    "<a name=\"eliminaciondevariablesinnecesarias\"></a>\n",
    "## 📌 **Eliminar y adecuar datos**\n",
    "\n",
    "\n",
    "Para optimizar el procesamiento se ha optado por los siguientes cambios:\n",
    "\n",
    "| **Acción** | **Descripción** | **Variables Afectadas** |\n",
    "|------------|----------------|------------------------|\n",
    "| **Eliminar Datos Meteorológicos** | No se utilizarán en el modelo, por lo que se descartan. | `tmin`, `tmed`, `tmax`, `horatmin`, `horatmax`, `hrMin`, `hrMedia`, `hrMax`, `horaHrMin`, `horaHrMax` |\n",
    "| **Eliminar Variables de Referencia de Color** | Se usaban solo para calcular ΔE, sin aportar valor directo a la predicción. | `L_base`, `A_base`, `B_base`, `Delta_E` |\n",
    "| **Variables Conservadas** | Conjunto final de variables seleccionadas para la predicción. | `estado`, `velocidad`, `L`, `A`, `B`, `patron_id`, `hour_sin`, `hour_cos`, `duracion_parada_anterior`, `tiempo_en_estado`, `seq_time` |\n",
    "| **Cambio de Índice** | Se usa `seq_time` en lugar del índice datetime para preservar la secuencia después de eliminar filas con `estado = 'parada'`. | `seq_time` como nuevo índice |\n",
    "\n",
    "<a name=\"transformacionesdedatos\"></a>\n",
    "## 📌 **Transformaciones de datos**\n",
    "\n",
    "A continuación se muestra un resumen en formato tabular de las distintas **etapas de transformación** de los datos:\n",
    "\n",
    "| **Etapa**                                 | **Variables Afectadas**                                                 | **Descripción**                                                                                                                                                | **Detalles/Referencias**                                                                                                     |\n",
    "|-------------------------------------------|--------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **1. Transformaciones logarítmicas**      | - `duracion_parada_anterior` <br/> - `tiempo_en_estado`                 | Se aplica logaritmo para reducir la asimetría (skew) en la distribución de dichas variables.                                                                   | Ver “Transformaciones logarítmicas” en [03_AnalisisDeDatos.ipynb](#anexos).                                                 |\n",
    "| **2. Escalado y normalización (numéricas)** | **Con StandardScaler:** <br/> - `velocidad` <br/> - `L`, `A`, `B` <br/> - `tiempo_en_estado` (ya log-transform) <br/><br/> **Con RobustScaler:** <br/> - `duracion_parada_anterior` (tras el log) | **StandardScaler()** se emplea para uniformar la escala y facilitar la convergencia del modelo. <br/><br/> **RobustScaler()** se utiliza para atenuar el efecto de valores atípicos en la variable `duracion_parada_anterior`. | Ver “Transformaciones con StandardScaler()” y “Transformaciones con RobustScaler()” en [03_AnalisisDeDatos.ipynb](#anexos). |\n",
    "| **3. Transformación de variables categóricas** | - `patron_id` <br/> - `estado` (después de eliminar filas con `estado = 'parada'`) | Se emplea **codificación one-hot** para evitar colinealidad y dada la baja cardinalidad de las categorías, no se requieren embeddings.                          | Ver “Transformaciones variables categóricas con one-hot” en [03_AnalisisDeDatos.ipynb](#anexos).                             |\n",
    "\n",
    "Se pueden consultar los gráficos de los [datos escalados aquí](https://github.com/laperl/MasterIA/blob/main/Resultados/DatosEscalados.jpg)\n",
    "\n",
    "**Resumen del análisis de datos escalados:**\n",
    "\n",
    "- **El escalado es adecuado** y mantiene las estructuras originales sin distorsiones severas.  \n",
    "- **L_scaled muestra una distribución bimodal**, mientras que **A_scaled y B_scaled son multimodales**, lo que sugiere la necesidad de técnicas avanzadas como embeddings si se usan Transformers.  \n",
    "- **Velocidad escalada tiene picos bien definidos**, reflejando los estados operativos de la máquina, pero puede requerir balanceo para evitar sesgos.  \n",
    "- **Tiempo en estado y duración de parada presentan sesgos**, con la última mostrando una gran concentración en un rango específico y colas largas, lo que podría afectar la predicción. Así y todo, en un inicio se ha decidido de conservarlas de esta manera\n",
    "\n",
    "<a name=\"matrizdecorrelacion\"></a>\n",
    "## 📌 **Matriz de correlación**\n",
    "\n",
    "Aunque los modelos basados en LSTM y Transformers pueden capturar relaciones complejas incluso con variables correlacionadas, se realizó un análisis para detectar posibles redundancias.  \n",
    "El análisis mostró que no existen correlaciones muy fuertes que puedan afectar negativamente al modelo.\n",
    "\n",
    "La [matriz de correlación también se puede visualizar aquí](https://github.com/laperl/MasterIA/blob/main/Resultados/MatrizCorrelacion.jpg)\n",
    "\n",
    "<a name=\"divisionentrenuestrosconjuntos\"></a>\n",
    "## 📌 **División en conjuntos de Train/Test/Validación**\n",
    "\n",
    "> *Implementación completa y descrición técnica en el notebook **04_ArreglosFinalesDatos.ipynb** (ver [anexo](#anexos))*.\n",
    "\n",
    "Ahora que ya tenemos los datos preparados, los dividiremos en las diferentes muestras para ser luego tratados. Las divisiones son correlativas es decir, van en orden y las proporciones son las siguientes:\n",
    "\n",
    "- **80% para entrenamiento (Train)**\n",
    "- **10% para validación (Validation)**\n",
    "- **10% para prueba (Test)**\n",
    "\n",
    "Es importante destacar que no se utiliza el \"shuffle\" en esta división, ya que se debe preservar el orden temporal para modelos secuenciales.  \n",
    "\n",
    "---\n",
    "\n",
    "<!-- Sección 6: Modelado -->\n",
    "<a name=\"modelado\"></a>\n",
    "# **6. Modelado**\n",
    "\n",
    "> *Implementación completa y descrición técnica en el notebook **05a_ModeloRNN-DirectApproach.ipynb** y **05b_Transformers.ipynb** (ver [anexo](#anexos))*.\n",
    "\n",
    "<a name=\"definiciondelmodelado\"></a>\n",
    "## 📌 **Definición del Modelado y Selección de Métricas**\n",
    "\n",
    "<a name=\"metricasdeevaluacion\"></a>\n",
    "### **Métricas de Evaluación Utilizadas**\n",
    "\n",
    "El objetivo del modelo es **predecir valores numéricos** que representan los colores **L, A y B** en un instante de tiempo futuro. Dado que no se trata de un problema de clasificación, sino de **regresión**, las métricas seleccionadas deben medir la precisión de los valores predichos.\n",
    "\n",
    "El equipo ha determinado que la métrica principal será el **Error Cuadrático Medio (MSE - Mean Squared Error)**, ya que penaliza más los errores grandes y proporciona estabilidad en la evaluación. Adicionalmente, también se calculará el **Error Absoluto Medio (MAE - Mean Absolute Error)** como métrica complementaria.\n",
    "\n",
    "<a name=\"consideracionessobrelasarquitecturas\"></a>\n",
    "### **Consideraciones sobre la Arquitectura de los Modelos**\n",
    "\n",
    "En el proceso de impresión, hay un desfase entre el momento en que se aplica la tinta y el instante en que el sensor mide el color final. Como cada máquina tiene un desfase distinto, se ha configurado el modelo para que este valor sea un **parámetro ajustable**.\n",
    "\n",
    "<a name=\"comparacionrnntransformers\"></a>\n",
    "### **Comparación de Enfoques**\n",
    "\n",
    "Se evaluaron diferentes enfoques para abordar el problema, comparando sus ventajas y desventajas:\n",
    "\n",
    "| **Enfoque**               | **Descripción**                                                        | **Ventajas**                                                                     | **Limitaciones en Series Temporales**                                                                                     |\n",
    "|---------------------------|------------------------------------------------------------------------|-----------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Regresión Lineal**      | Encuentra una relación lineal entre variables.                         | - Rápida y fácil de interpretar.                                                  | - No captura relaciones complejas ni dependencias temporales. <br/>- Tiende a subestimar la dinámica no lineal.           |\n",
    "| **Redes Neuronales MLP**  | Redes densas que aprenden patrones no lineales a partir de datos.      | - Aproximación versátil en datos bien estructurados.                              | - No maneja secuencias de forma nativa.<br/>- Precisa técnicas extras (ventanas, codificación) para retener orden temporal. |\n",
    "| **RNN (Recurrentes)**     | Redes diseñadas para procesar datos secuenciales paso a paso.          | - Capturan relaciones temporales inmediatas.                                      | - Problema de desvanecimiento de gradiente en secuencias largas.<br/>- Menor eficacia con dependencias muy prolongadas.   |\n",
    "| **GRU**                   | Variante de RNN con puertas de control (Gated Recurrent Units).        | - Más eficiente que LSTM y con menos problemas de gradientes.                     | - Menos expresivo que LSTM en secuencias muy extensas.<br/>- Puede no captar patrones de muy largo plazo con igual eficacia. |\n",
    "| **LSTM**                  | RNN con memoria a largo plazo (Long Short-Term Memory).                | - Maneja mejor las dependencias largas y el gradiente.                            | - Entrenamiento más lento y mayor coste computacional que GRU.<br/>- Requiere más datos y potencia en secuencias muy largas. |\n",
    "| **Transformers**          | Modelo basado en autoatención (*self-attention*).                      | - Excelente para dependencias de amplio alcance.<br/>- Muy eficiente en paralelo. | - Alto consumo de memoria en secuencias largas (complejidad cuadrática).<br/>- Menos práctico sin técnicas como *sparse attention*. |\n",
    "| **Wave (p. ej. WaveNet)** | Arquitecturas creadas para señales continuas (audio) y convoluciones.  | - Capturan patrones a múltiples escalas.<br/>- Útiles en generación de señales.   | - Adaptación a series no-audio no siempre trivial.<br/>- Elevado consumo de recursos si los datos son muy heterogéneos.   |\n",
    "| **DeepSeek/GPT**          | Modelos preentrenados (p. ej. GPT) que pueden adaptarse con *fine-tuning*. | - Aprovechan el *transfer learning* de grandes corpus.<br/>- Capturan relaciones a largo plazo. | - Requieren recursos computacionales muy elevados.<br/>- No siempre reflejan bien la estructura temporal numérica (ciclos, estacionalidad). |\n",
    "\n",
    "**Nota**:  \n",
    "- En el caso de **Wave** (WaveNet, WaveRNN), aunque su diseño inicial está muy orientado a señales de audio, pueden reutilizarse en **otros entornos de serie temporal** con modificaciones específicas en la arquitectura de convoluciones dilatadas y en los mecanismos de upsampling/downsampling.  \n",
    "- En el caso de **DeepSeek/GPT**, la mayor complejidad radica en alinear los datos numéricos o de serie temporal con el **formato de entrada textual** (o tokenizado) típico de GPT, así como en contar con **recursos computacionales** suficientes para un *fine-tuning* prolongado.\n",
    "- También se ha pensado en sistemas híbridos donde por ejemplo se usen Transformers mas una capa de GRU para llegar a un resultado más optimizado.\n",
    "\n",
    "**Decisión Final**\n",
    "\n",
    "Se decidió utilizar **GRU/LSTM y Transformers**, ya que son modelos diseñados para capturar dependencias temporales y han demostrado ser efectivos en tareas de predicción secuencial. Además se pueden entrenar en tiempos y computo razonables. No se excluye en un futuro probar otras aproximaciones en el caso que estas que se van a analizar no funcionen bien.\n",
    "\n",
    "<a name=\"configuracioninicial\"></a>\n",
    "## 📌 **Configuraciones y Parámetros Globales para todos los modelos implementados**\n",
    "\n",
    "Para probar diferentes enfoques, se utilizó **TensorFlow para los modelos LSTM/GRU** y **PyTorch para Transformers**.\n",
    "\n",
    "<a name=\"tamanoventana\"></a>\n",
    "### **Desfase y Tamaño de Ventana**\n",
    "- Se estableció un **desfase de 4 pasos**: cuando la máquina imprime en el instante *t*, el color objetivo se mide en *t+4*.\n",
    "- Se fijó el **tamaño de la ventana en 30** para ambos enfoques (LSTM/GRU y Transformers). Esta elección se basa en que, con los datos disponibles, una ventana de este tamaño parece apropiada y equilibrada para realizar comparaciones.\n",
    "\n",
    "**Importancia del Tamaño de la Ventana**\n",
    "\n",
    "| Enfoque         | Ventanas Pequeñas | Ventanas Grandes |\n",
    "|----------------|------------------|------------------|\n",
    "| **Redes Recurrentes (LSTM/GRU)** | Pueden no capturar suficiente contexto. | Pueden añadir ruido y dificultar el entrenamiento. |\n",
    "| **Transformers** | Reducen carga computacional pero pueden perder contexto. | Capturan más información pero aumentan el costo computacional. |\n",
    "\n",
    "**Conclusión:** Se encontró que un **tamaño de ventana de 30** proporciona un buen equilibrio entre precisión y eficiencia.\n",
    "\n",
    "<a name=\"reproducibilidad\"></a>\n",
    "### **Reproducibilidad**\n",
    "\n",
    "Para asegurar que los experimentos sean **reproducibles**, he utilizado una configuración específica de parámetros, incluyendo **semillas de aleatoriedad**. Esto significa que, aunque algunos procesos en aprendizaje automático pueden generar resultados diferentes cada vez que se ejecutan, al establecer estas semillas garantizo que los modelos se entrenen siempre con los mismos valores iniciales, permitiendo obtener resultados consistentes.\n",
    "\n",
    "En este caso, he aplicado semillas de aleatoriedad en varias librerías clave:\n",
    "\n",
    "- **TensorFlow y Pytorch**: Para controlar cómo se inicializan los pesos de la red neuronal y otros procesos internos.\n",
    "- **Random (Python)**: Para cualquier operación que dependa de números aleatorios, como la división de los datos en entrenamiento y prueba.\n",
    "- **CUDA y cuDNN**: Son tecnologías utilizadas para acelerar el entrenamiento con GPU. Sin fijar la aleatoriedad en estos sistemas, el uso de múltiples núcleos podría generar ligeras variaciones en los resultados.\n",
    "\n",
    "Gracias a esta configuración, cualquier persona que ejecute el mismo código debería obtener los **mismos resultados**, lo que es fundamental para comparar modelos y evaluar mejoras de manera objetiva.\n",
    "\n",
    "<a name=\"optimizaciones\"></a>\n",
    "### **Optimizaciones**\n",
    "\n",
    "**Callbacks**\n",
    "\n",
    "Para todos los modelos GRU, LSTM, Transformers se utilizaron las siguientes estrategias de optimización:\n",
    "\n",
    "1. **Early Stopping** para evitar sobreajuste.  \n",
    "2. **ReduceLROnPlateau** para ajustar dinámicamente el *learning rate*.  \n",
    "3. **Time Callback** para medir la duración del entrenamiento.  \n",
    "\n",
    "\n",
    "<a name=\"implementaciondemodelos\"></a>\n",
    "## 📌 **Implementación de los Modelos elegidos**\n",
    "\n",
    "<a name=\"rnnbasadosmodelos\"></a>\n",
    "### 📌 **Modelos Basados en RNN (LSTM y GRU)**\n",
    "\n",
    "> *Implementación completa, entrenamientos y descrición técnica en el notebook **05a_ModeloRNN-DirectApproach.ipynb** (ver [anexo](#anexos))*.\n",
    "\n",
    "\n",
    "<a name=\"decisionesclavegrulstm\"></a>\n",
    "### **Decisiones Clave en la Arquitectura**\n",
    "\n",
    "- Reciben una **ventana de 30 pasos** como entrada.\n",
    "- Utilizan **dos capas LSTM/GRU** para extraer patrones temporales.\n",
    "- La segunda capa devuelve solo el último estado, prediciendo el color en *t+4*.\n",
    "- Se añaden **Batch Normalization y Regularización L2** para mejorar estabilidad y evitar sobreajuste.\n",
    "\n",
    "- **¿LSTM o GRU?** Se evaluaron ambas arquitecturas y no se encontraron diferencias significativas en el rendimiento.\n",
    "- **¿Por qué no usar Seq2Seq?** Aunque se probó, el modelo Seq2Seq añadió complejidad innecesaria y aumentó el tiempo de entrenamiento, sin mejorar las predicciones. Dado que la tarea no requiere generar secuencias completas, sino predecir valores en un tiempo específico *t*, su uso no es justificado.\n",
    "- **¿Por qué no RNNs simples?** Las RNN tradicionales pueden enfrentar dificultades al capturar dependencias a largo plazo debido al problema del desvanecimiento del gradiente, las descarté sin probar aunque podrían haberse considerado.\n",
    "- **¿Por qué dos capas?** Se experimentó con configuraciones de 1, 2 y 3 capas, determinando que una arquitectura de **dos capas** ofrecía el mejor equilibrio entre complejidad y rendimiento, además de mejores resultados.\n",
    "- **¿Por qué Normalización y Regularización?** Para mitigar el sobreajuste observado durante el entrenamiento, se implementaron técnicas de normalización y regularización, mejorando la capacidad de generalización del modelo.\n",
    "- **Optimización con Adam y AMSGrad:** Estas técnicas de optimización se emplearon para mejorar la estabilidad y eficiencia del proceso de entrenamiento. Con **AMSGrad** lograba también reproducibilidad.\n",
    "\n",
    "<a name=\"optimizacionhiperparametros\"></a>\n",
    "#### **Optimización y Ajuste de Hiperparámetros**\n",
    "\n",
    "Se probaron múltiples configuraciones mediante búsqueda en cuadrícula (*Grid Search*).  \n",
    "Las mejores configuraciones fueron:\n",
    "\n",
    "| **Parámetro** | **Valores Evaluados** | **Configuración Final** |\n",
    "|--------------|------------------|------------------|\n",
    "| **Número de neuronas (latent_dim)** | 16, 32 | **32** |\n",
    "| **Dropout** | 0.4 - 0.8 | **0.5** |\n",
    "| **Learning Rate** | 1e-4 a 1e-5 | **1e-4** |\n",
    "| **Batch Size** | 32, 64 | **32** |\n",
    "| **Tipo de RNN** | LSTM, GRU | **LSTM** |\n",
    "\n",
    "---\n",
    "\n",
    "<a name=\"transformersbasadosmodelos\"></a>\n",
    "### 📌 **Modelos Basados en Transformers**\n",
    "\n",
    "> *Implementación completa, entrenamientos y descrición técnica en el notebook **06_AnalisiResultados_RNN.ipynb** (ver [anexo](#anexos))*.\n",
    "\n",
    "<a name=\"consideracionessobrelasarquitecturas\"></a>\n",
    "#### **Consideraciones sobre la Arquitectura del Modelo**\n",
    "\n",
    "En este caso, solo se implementa el **Encoder del Transformer**, sin utilizar un Decoder.  \n",
    "Esto se debe a que **no estamos generando una secuencia de salida**, sino prediciendo **tres valores finales** (L, A, B).\n",
    "\n",
    "📌 **Razones para usar solo el Encoder:**\n",
    "\n",
    "- **No se necesita generación de secuencias:** El modelo debe aprender representaciones temporales y producir un único vector de salida.\n",
    "- **Reducción de costo computacional:** Usar solo el Encoder permite un entrenamiento más eficiente sin afectar la precisión.\n",
    "- **Mejor manejo de relaciones a largo plazo:** El mecanismo de atención de los Transformers captura patrones en secuencias largas sin problemas de desvanecimiento del gradiente.\n",
    "\n",
    "**Codificación posicional**\n",
    "\n",
    "En modelos como los Transformers, los datos se procesan como secuencias de tokens (como palabras, números o pasos temporales). Sin embargo:\n",
    "\n",
    "* **Transformers** *no entienden el orden natural de los datos* porque no procesan la información de izquierda a derecha como las RNN (redes recurrentes).\n",
    "* Para que el modelo pueda distinguir la posición de cada token en la secuencia (por ejemplo, \"1º, 2º, 3º...\"), se utiliza una codificación posicional.\n",
    "\n",
    "Se generó una **clase `CodificacionPosicional`** (que podemos ver en el notebook correspondiente) que añade información sobre la posición de cada elemento en la secuencia usando valores basados en funciones matemáticas (seno y coseno).\n",
    "\n",
    "<a name=\"optimizacionhiperparametros_transformers\"></a>\n",
    "### **Optimización y Ajuste de Hiperparámetros en Transformers**\n",
    "\n",
    "Se probaron múltiples configuraciones mediante búsqueda en cuadrícula (*Grid Search*).  \n",
    "Las mejores configuraciones fueron:\n",
    "\n",
    "| **Parámetro** | **Valores Evaluados** | **Descripción** |\n",
    "|--------------|------------------|------------------|\n",
    "| **d_model (Dimensión del Modelo)** | 32, 64, 128 | Define el tamaño del vector de representación en cada token de entrada. Mayor valor aumenta la capacidad de representación, pero también el costo computacional. Debe ser múltiplo de `nhead`. |\n",
    "| **nhead (Número de Cabezas de Atención)** | 2, 4, 8 | Número de cabezas en la atención multi-cabeza. Más cabezas permiten aprender relaciones más complejas, pero aumentan el cómputo. `d_model` debe ser divisible por `nhead`. |\n",
    "| **num_layers (Capas del Encoder)** | 1, 2, 3 | Cantidad de capas Transformer apiladas. Más capas mejoran la captura de relaciones a largo plazo, pero aumentan el riesgo de sobreajuste y el costo computacional. |\n",
    "| **dim_feedforward (Tamaño de la Red Feedforward)** | 64, 128, 256 | Tamaño de la capa oculta dentro de cada bloque Transformer. Un valor mayor mejora la expresividad del modelo, pero aumenta la memoria y el tiempo de entrenamiento. |\n",
    "| **Dropout** | 0.1, 0.2, 0.3 | Técnica de regularización que desactiva neuronas aleatoriamente para evitar sobreajuste. Valores muy altos (>0.5) pueden hacer que el modelo pierda información útil. Usualmente 0.1 o 0.2 en Transformers. |\n",
    "| **Learning Rate** | 1e-4 a 1e-5 | Controla la velocidad de ajuste de los pesos del modelo. Un valor muy alto puede impedir la convergencia, y uno muy bajo puede hacer el entrenamiento demasiado lento. |\n",
    "| **Batch Size** | 32, 64 | Cantidad de ejemplos procesados en cada iteración de entrenamiento. Batches más grandes estabilizan el entrenamiento, pero requieren más memoria. |\n",
    "\n",
    "> *Implementación completa y descrición técnica en el notebook **05b_Transformers.ipynb** (ver [anexo](#anexos))*.\n",
    "\n",
    "---\n",
    "\n",
    "Este apartado resume el proceso de modelado, selección de arquitecturas, ajuste de hiperparámetros y evaluación de modelos. Ahora, con los modelos entrenados, se procede a su comparación en la siguiente sección. 🚀\n",
    "\n",
    "---\n",
    "\n",
    "<!-- Sección 7: Evaluación y Comparación de Modelos -->\n",
    "<a name=\"evaluacionycomparaciondemodelos\"></a>\n",
    "# **7. Evaluación y Comparación de Modelos**\n",
    "\n",
    "<a name=\"observacionesglobalesgrulstmtransformers\"></a>\n",
    "## Observaciones Globales en Modelos GRU, LSTM y Transformers\n",
    "\n",
    "1. **Ampliación del tamaño de datos**  \n",
    "   - Inicialmente, se disponía de un total de 80.000 ejemplos sintéticos, pero los resultados eran insatisfactorios: el modelo tardaba en converger y no capturaba bien los patrones subyacentes.  \n",
    "   - Al ampliar el conjunto de datos a **más de 200.000** ejemplos, el modelo mostró un comportamiento más estable, si bien no definitivamente óptimo. En escenarios reales con datos muy variables, se requeriría probablemente un volumen de datos todavía mayor para obtener resultados más contundentes.\n",
    "\n",
    "2. **Tamaño de ventana (Window Size)**  \n",
    "   - Se realizaron pruebas con *window sizes* de 20 y 30, sin diferencias excesivamente significativas. Sin embargo, un *window size* de **30** ofreció ligeras mejoras y, por ello, se mantuvo como la configuración principal. Esto concuerda con la idea de que, en sistemas industriales, disponer de un contexto temporal más amplio (aun sin ser enorme) puede facilitar la detección de tendencias.\n",
    "\n",
    "3. **Registro de métricas sólo en el mejor modelo de cada experimento**  \n",
    "   - Se optó por registrar la *predictions_loss_mse* (u otras métricas) únicamente en la configuración con mejor validación de cada ensayo, para agilizar el proceso y focalizar el análisis.  \n",
    "   - Aun así, se reconoce que calcular dichas métricas en todos los modelos podría arrojar más luz sobre la estabilidad y consistencia del entrenamiento. En futuras iteraciones, se valora un registro más exhaustivo.\n",
    "\n",
    "Evidentemente a medida que hemos ido avanzando en los entrenamientos hemos ido acotando y refinando la parametrización \n",
    "\n",
    "<a name=\"evaluaciongru\"></a>\n",
    "## Evaluación GRU\n",
    "\n",
    "> *El notebook que analiza los resultados para GRU y LSTM es  **06_AnalisisResultados_RNN.ipynb** (ver [anexo](#anexos))*.\n",
    "\n",
    "<a name=\"resultadosexperimentogru\"></a>\n",
    "### Resultados de los experimentos GRU\n",
    "\n",
    "Para no llenar este apartado de resultados, se ha decidido enlazarlos a GitHub, lo que permite una mejor organización y claridad:\n",
    "\n",
    "| 📌 **Experimento** | 📊 **Tabla de Resultados** | 📈 **Learning Curves** |\n",
    "|-------------------|--------------------|----------------|\n",
    "| **Experimento 1** | [📊 Tabla de resultados](https://github.com/laperl/MasterIA/blob/main/Resultados/01_GRU_TablaResultados.jpg) | - [📈 Learning Curve 1](https://github.com/laperl/MasterIA/blob/main/Resultados/01_GRU_LearningCurves_1.jpg) <br> - [📉 Learning Curve 2](https://github.com/laperl/MasterIA/blob/main/Resultados/01_GRU_LearningCurves_2.jpg) |\n",
    "| **Experimento 2** | [📊 Tabla de resultados](https://github.com/laperl/MasterIA/blob/main/Resultados/02_GRU_TablaResultados.jpg) | - [📈 Learning Curve 1](https://github.com/laperl/MasterIA/blob/main/Resultados/02_GRU_LearningCurves.jpg) |\n",
    "| **Otros experimentos** | [📊 Tabla de resultados](https://github.com/laperl/MasterIA/blob/main/Resultados/034567_TablaResultados_GRU.jpg) | - [📈 Learning Curve 4](https://github.com/laperl/MasterIA/blob/main/Resultados/03_GRU_LearningCurves.jpg) <br> - [📉 Learning Curve 5](https://github.com/laperl/MasterIA/blob/main/Resultados/05_GRU_LearningCurves.jpg) <br> - [📈 Learning Curve 6](https://github.com/laperl/MasterIA/blob/main/Resultados/06_GRU_LearningCurves.jpg) <br> - [📉 Learning Curve 7](https://github.com/laperl/MasterIA/blob/main/Resultados/07_GRU_LearningCurves.jpg) |\n",
    "\n",
    "<a name=\"conclusionesgru\"></a>\n",
    "### Conclusiones GRU\n",
    "\n",
    "1. **Elección de la tasa de aprendizaje (Learning Rate)**  \n",
    "   - Se evaluaron diferentes valores de *learning rate*, principalmente en el rango de \\(10^{-4}\\) y \\(10^{-5}\\). Se constató que **\\(10^{-5}\\)** ofrecía una mejor estabilidad y evitaba la “explosión de gradientes”, lo que resulta especialmente relevante en un contexto de datos con alta variabilidad sintética.  \n",
    "   - Se descartaron valores de *learning rate* inferiores a \\(10^{-5}\\) (por ejemplo, \\(10^{-6}\\) o \\(10^{-7}\\)) debido a su lenta convergencia y a la escasa mejora obtenida tras numerosas iteraciones.  \n",
    "   - Otras tasas intermedias, como \\(6.5 \\times 10^{-5}\\) o \\(5 \\times 10^{-5}\\), no evidenciaron un desempeño tan estable como el de \\(10^{-5}\\).\n",
    "\n",
    "2. **Regularización y presencia de sobreajuste**  \n",
    "   - En los primeros ensayos, se apreciaba un sobreajuste significativo incluso con *dropout* moderado (0.3–0.5). Ello se atribuyó, en gran medida, a la **aleatoriedad inherente** de los datos sintéticos y a que el conjunto de datos poseía “zonas” muy heterogéneas.  \n",
    "   - **El *dropout* de 0.7** terminó siendo el que proporcionó una mayor capacidad de contención del sobreajuste, ayudado por **Batch Normalization** y la **Regularización L2**. Esta combinación atenuó las fluctuaciones en el error de validación y estabilizó el entrenamiento, a pesar del incremento en la dificultad de aprendizaje que supone un *dropout* elevado.  \n",
    "   - Para mejorar la generalización, también se añadieron capas de normalización por lotes (*batch normalization*), que contribuyeron a moderar los picos de pérdida y facilitar una convergencia más suave.\n",
    "\n",
    "3. **Batch Size**  \n",
    "   - Se probaron diversos *batch sizes* (16, 32, 64), observándose que **32** generaba un mejor equilibrio entre estabilidad del gradiente y velocidad de convergencia. Con *batch sizes* más pequeños, se apreciaba cierta inestabilidad, y con valores mayores, la capacidad de ajuste parecía reducirse ligeramente.\n",
    "\n",
    "4. **Dimensiones internas del modelo (16, 32 o 64 neuronas)**  \n",
    "   - No se identificó una tendencia inequívoca a favor de un número de neuronas claramente superior o inferior en todas las circunstancias. Por ejemplo, redes con 16 neuronas en la capa GRU pueden converger de forma estable, mientras que 32 y 64 no siempre mostraron ventajas marcadas.\n",
    "   - Más experimentos son necesarios para establecer, pero probablemente en el caso de datos sintéticos, las muestras para Train tienen que ser mucho más grandes.\n",
    "\n",
    "5. **Comparación de Pérdidas de Entrenamiento vs. Validación**  \n",
    "   - En diversos experimentos, se observó que la pérdida (loss) en validación llegaba a ser **incluso menor** que la de entrenamiento. Una posible explicación es la relativa homogeneidad de la porción de validación, o bien diferencias de distribución en los lotes.  \n",
    "   - Si la selección del bloque de validación contiene intervalos menos variables, el modelo puede ajustarse con mayor facilidad en dicha parte. En escenarios reales, esto subraya la importancia de garantizar una partición representativa entre entreno y validación.\n",
    "\n",
    "**Reflexión Final**\n",
    "\n",
    "En síntesis, **los experimentos confirman que un *learning rate* reducido (\\(10^{-5}\\)) y un *dropout* relativamente alto (0.7) pueden ofrecer un balance óptimo** para combatir el sobreajuste en datos sintéticos con alta aleatoriedad. A ello se suma la conveniencia de ampliar el volumen de muestras (por encima de 200k) y mantener un *window size* suficiente (en torno a 30 o más) para capturar la dinámica temporal. No obstante, en un escenario industrial real, **sería recomendable** complementar estos hallazgos con un mayor control de la variabilidad externa, un ajuste cuidadoso de la partición de validación y, por supuesto, la incorporación de datos empíricos para refinar la arquitectura y la regularización.\n",
    "\n",
    "---\n",
    "\n",
    "<a name=\"evaluacionlstm\"></a>\n",
    "## Evaluación LSTM\n",
    "\n",
    "> *El notebook que analiza los resultados para GRU y LSTM es  **06_AnalisisResultados_RNN.ipynb** (ver [anexo](#anexos))*.\n",
    "\n",
    "<a name=\"resultadosexperimentolstm\"></a>\n",
    "### Resultados de los experimentos LSTM\n",
    "\n",
    "Para no llenar este apartado de resultados, se ha decidido enlazarlos a GitHub, lo que permite una mejor organización y claridad:\n",
    "\n",
    "| 📌 **Experimento** | 📊 **Tabla de Resultados** | 📈 **Learning Curves** |\n",
    "|-------------------|--------------------|----------------|\n",
    "| **Experimento 1** | [📊 Tabla de resultados](https://github.com/laperl/MasterIA/blob/main/Resultados/01_LSTM_TablaResultados.jpg) | - [📉 Learning Curve 1](https://github.com/laperl/MasterIA/blob/main/Resultados/01_LSTM_LearningCurves.jpg) |\n",
    "| **Experimento 2** | [📊 Tabla de resultados](https://github.com/laperl/MasterIA/blob/main/Resultados/02_LSTM_TablaResultados.jpg) | - [📈 Learning Curve 1](https://github.com/laperl/MasterIA/blob/main/Resultados/02_LSTM_LearningCurves.jpg) |\n",
    "| **Otros experimentos** | [📊 Tabla de resultados](https://github.com/laperl/MasterIA/blob/main/Resultados/034567_TablaResultados_LSTM.jpg) | - [📈 Learning Curve 2](https://github.com/laperl/MasterIA/blob/main/Resultados/03_LSTM_LearningCurves.jpg) <br> - [📉 Learning Curve 4](https://github.com/laperl/MasterIA/blob/main/Resultados/04_LSTM_LearningCurves.jpg) <br> - [📈 Learning Curve 5](https://github.com/laperl/MasterIA/blob/main/Resultados/05_LSTM_LearningCurves.jpg) |\n",
    "\n",
    "<a name=\"conclusioneslstm\"></a>\n",
    "### Conclusiones LSTM\n",
    "\n",
    "1. **Elección de la tasa de aprendizaje (Learning Rate)**  \n",
    "   - En el caso de LSTM, lo mismo que en GRU; no funcionaron valores bajos de learning rate, el que mejor funcionó fue de nuevo **\\(10^{-5}\\)**.\n",
    "\n",
    "2. **Regularización y presencia de sobreajuste**  \n",
    "   - Siguen los valores dropout siendo altos aunque, los mejores modelos no necesitan de un dropout tan elevado como en el caso de GRU.\n",
    "   - Para mejorar la generalización, también se añadieron capas de normalización por lotes (*batch normalization*), que contribuyeron a moderar los picos de pérdida y facilitar una convergencia más suave.\n",
    "\n",
    "3. **Batch Size**  \n",
    "   - Al igual que con las GRU, se probaron diversos *batch sizes* (16, 32, 64), observándose que **32** generaba un mejor equilibrio entre estabilidad del gradiente y velocidad de convergencia. Con *batch sizes* más pequeños, se apreciaba cierta inestabilidad, y con valores mayores, la capacidad de ajuste parecía reducirse ligeramente.\n",
    "\n",
    "4. **Dimensiones internas del modelo (16, 32 o 64 neuronas)**  \n",
    "   - No se identificó una tendencia inequívoca a favor de un número de dimensiones claramente superior o inferior en todas las circunstancias. Curiosamente, a diferencia de las GRU, en este caso la tendencia del modelo ganador es con 64 dimensiones.\n",
    "   - La elección final no está clara y habría que hacer más pruebas, de todas maneras, seguir buscando con valores de 16 y sobretodo 64 parece lo más óptimo.\n",
    "\n",
    "5. **Comparación de Pérdidas de Entrenamiento vs. Validación**  \n",
    "   - Sucede lo mismo que en GRU. En diversos experimentos, se observó que la pérdida (loss) en validación llegaba a ser **incluso menor** que la de entrenamiento. Una posible explicación es la relativa homogeneidad de la porción de validación, o bien diferencias de distribución en los lotes.  \n",
    "   - Si la selección del bloque de validación contiene intervalos menos variables, el modelo puede ajustarse con mayor facilidad en dicha parte. En escenarios reales, esto subraya la importancia de garantizar una partición representativa entre entreno y validación.\n",
    "\n",
    "**Reflexión Final**\n",
    "\n",
    "No queda claro si funciona mejor LSTM o GRU, hacen falta más experimentos para llegar a una conclusión, lo que está claro es que el error medio de MSE está entorno 1 lo cual no es una buena noticia.\n",
    "\n",
    "Se pueden ver la comparativa de los mejores resultados de LSTM y GRU [en este gráfico](https://github.com/laperl/MasterIA/blob/main/Resultados/ResultadosAgregados_GRU_LSTM.jpg).\n",
    "\n",
    "---\n",
    "\n",
    "<a name=\"evaluaciontransformers\"></a>\n",
    "## Evaluación Transformers\n",
    "\n",
    "> *Implementación completa y descrición técnica en el notebook **05b_Transformers.ipynb** (ver [anexo](#anexos))*.\n",
    "\n",
    "Tras entrenar los modelos con **window_size de 30, offset de 4** y un **batch_size de 128** pues fue el que mejor resultado nos dio, se obtuvieron los siguientes resultados que pueden verse en Github:\n",
    "\n",
    "- [Tabla de resultados](https://github.com/laperl/MasterIA/blob/main/Resultados/TransformersResultados.jpg)\n",
    "- [Learning Curves 1](https://github.com/laperl/MasterIA/blob/main/Resultados/01_Transformers_LearningCurves_1.jpg), [Learning Curves 2](https://github.com/laperl/MasterIA/blob/main/Resultados/01_Transformers_LearningCurves_2.jpg)\n",
    "\n",
    "El mejor modelo obtuvo un resultado de **0.8989** (Loss MSE) en la muestra de **Test**.\n",
    "\n",
    "<a name=\"conclusionestransformers\"></a>\n",
    "### Conclusiones Transformers\n",
    "\n",
    "- **Necesidad de más datos**  \n",
    "  Incluso con *dropout* alto, se observó sobreajuste; los *Transformers* suelen exigir un volumen de datos mayor para aprovechar al máximo su mecanismo de atención.\n",
    "\n",
    "- **Persistencia de sobreajuste**  \n",
    "  A pesar del uso de *dropout* elevados, los modelos finales no generalizan bien en validación, indicio de que la capacidad del modelo excede la información disponible.\n",
    "\n",
    "- **Convergencia más rápida con 128 y `nhead=8`**  \n",
    "  Los *Transformers* que emplean `d_model=128` y `nhead=8` tienden a converger en menos épocas que configuraciones mayores, presumiblemente por menor complejidad.\n",
    "\n",
    "- **Cabezas de Atención**  \n",
    "  La configuración de 8 cabezas (*nhead=8*) funcionó mejor; incrementar el número de cabezas podría mejorar los resultados, pero también aumentaría el coste computacional.\n",
    "\n",
    "- **Número de capas**  \n",
    "  Se evaluaron 1, 2 y 3 capas; las de 3 no aportaron mejoras y complicaron el entrenamiento, por lo que se simplificó a 1 o 2 capas.\n",
    "\n",
    "- **Learning Rate heredado de GRU/LSTM**  \n",
    "  Se usó el mismo valor que funcionó en GRU y LSTM. *ReduceLROnPlateau* ajustó dinámicamente la tasa, mostrando un comportamiento aceptable pero no exhaustivamente optimizado.\n",
    "\n",
    "- **Curvas de entrenamiento vs. validación**  \n",
    "  La validación suele finalizar por encima de la pérdida de entrenamiento, lo cual sugiere que el *Transformer* es capaz de sobreajustarse más fácilmente que las redes recurrentes.\n",
    "\n",
    "**Reflexión Final**\n",
    "\n",
    "No emergió un modelo claramente superior con los parámetros probados, aunque la configuración `d_model=128, nhead=8, layers=1, dim_feedforward=64, dropout=0.6, learning_rate=1e-5` mostró un desempeño algo mejor. La *loss* en validación y test sigue rondando 1, insuficiente para aplicaciones industriales. Es imprescindible investigar más parámetros y, sobre todo, **disponer de más datos** para que el *Transformer* despliegue todo su potencial.\n",
    "\n",
    "---\n",
    "\n",
    "<a name=\"elmejormodelo\"></a>\n",
    "## El mejor modelo\n",
    "\n",
    "No se encontró un ganador absoluto y, por ahora, ningún resultado puede llevarse a producción. Sin embargo, los **Transformers** podrían superar a GRU y LSTM con datos más numerosos, dado que su mecanismo de atención retiene información de todo el contexto de forma más directa. En cambio, **GRU y LSTM** sí pueden manejar dependencias a largo plazo, pero a menudo les resulta más difícil cuando la secuencia es muy extensa.\n",
    "\n",
    "Para quienes deseen comparar, los mejores resultados obtenidos en cada enfoque pueden visualizarse (**descargando los archivos, ya que GitHub no los muestra por su tamaño**):\n",
    "\n",
    "- [LSTM](https://github.com/laperl/MasterIA/blob/main/Resultados/visualizacion_LSTM4.html)  \n",
    "- [GRU](https://github.com/laperl/MasterIA/blob/main/Resultados/02_GRU_visualizacion.html)\n",
    "- [Transformers](https://github.com/laperl/MasterIA/blob/main/Resultados/01_Transformersvisualizacion.html)  \n",
    "\n",
    "---\n",
    "\n",
    "<!-- Sección 8: Conclusiones y Mejoras Futuras -->\n",
    "<a name=\"conclusionesymejorasfuturas\"></a>\n",
    "# **8. Conclusiones**\n",
    "\n",
    "<a name=\"conclusionesprincipalesestudioactual\"></a>\n",
    "## Conclusiones Principales del estudio actual\n",
    "\n",
    "1. **Necesidad de un gran histórico de datos / mediciones frecuentes**  \n",
    "   - **Motivo**: Los modelos secuenciales (RNN, LSTM/GRU, Transformers) requieren abundantes ejemplos para capturar patrones temporales y estacionales.  \n",
    "   - **Conclusión**: Aumentar la frecuencia de medición, o bien disponer de un mayor histórico, potencia de manera sustancial la capacidad predictiva.\n",
    "\n",
    "2. **Variables climáticas (humedad, temperatura) como potenciales mejoras**  \n",
    "   - **Motivo**: En entornos industriales de impresión, el clima influye en la adherencia y calidad del color.  \n",
    "   - **Conclusión**: Aunque las máquinas no suelen registrar dichas variables, su incorporación en un escenario real puede brindar mayor precisión y debería considerarse medirlas si fuera factible.\n",
    "\n",
    "3. **Limitaciones de los datos sintéticos**  \n",
    "   - **Motivo**: Un exceso de aleatoriedad o la falta de correlación con procesos reales distorsiona las conclusiones.  \n",
    "   - **Conclusión**: Los datos sintéticos sirven para prototipar, pero se recomienda realizar la validación final en condiciones reales con datos de la propia máquina.\n",
    "\n",
    "4. **Modelos actuales no aptos para producción**  \n",
    "   - **Motivo**: Todavía no se dispone de una validación industrial ni de un ajuste definitivo en situaciones reales.  \n",
    "   - **Conclusión**: Las soluciones actuales constituyen solo un punto de partida; es necesario refinarlas, re-entrenarlas y validarlas con información proveniente de la producción real.\n",
    "\n",
    "5. **Falta de comparación concluyente entre GRU/LSTM y Transformers**  \n",
    "   - **Motivo**: Ambos enfoques se han aplicado, pero no existe un resultado cuantitativo que identifique cuál es sistemáticamente superior.  \n",
    "   - **Conclusión**: Resulta imprescindible experimentar con más datos (o datos reales) para determinar cuál de los dos se adapta mejor al entorno industrial.\n",
    "\n",
    "6. **Tamaño de ventana común (30) para RNN y Transformers**  \n",
    "   - **Motivo**: Se unificó el tamaño de la secuencia para simplificar la experimentación.  \n",
    "   - **Conclusión**: Aun cuando esta uniformidad facilita la comparación, LSTM/GRU y Transformers interpretan el tamaño de ventana de forma distinta. Se sugiere evaluar diferentes longitudes para optimizar resultados en cada modelo.\n",
    "\n",
    "7. **Reproducibilidad y semilla**  \n",
    "   - **Motivo**: Aunque se fijen semillas en Python, NumPy, TensorFlow o PyTorch, el hardware (por ejemplo, GPU y cuDNN) puede introducir componentes no deterministas.  \n",
    "   - **Conclusión**: Es inviable alcanzar reproducibilidad total en todos los entornos; se recomienda documentar tanto la configuración de software como la de hardware, además de las semillas empleadas.\n",
    "\n",
    "8. **Conveniencia de seguir investigando**  \n",
    "   - **Motivo**: Ningún enfoque se ha consolidado como el mejor en presencia de datos sintéticos y un problema de alta complejidad.  \n",
    "   - **Conclusión**: Conviene continuar explorando redes recurrentes (RNN) y Transformers para identificar la solución más adecuada en cada caso.\n",
    "\n",
    "---\n",
    "\n",
    "<a name=\"mejorassiguientesiteraciones\"></a>\n",
    "## Mejoras para las siguientes iteraciones\n",
    "\n",
    "1. **Refinamiento de la variable `duracion_parada`**  \n",
    "   - Se sugiere reemplazarla o complementarla con un indicador binario (0/1: “viene de parada” o “no”) para atenuar la influencia de valores atípicos en la escala.\n",
    "\n",
    "2. **Diversificación de los datos sintéticos**  \n",
    "   - Conviene ajustar factores como el nivel de ruido, la duración de los estados y los rangos de velocidad, a fin de aproximar mejor situaciones reales y reducir la aleatoriedad excesiva.\n",
    "\n",
    "3. **Evaluación de optimizadores adicionales**  \n",
    "   - Se propone probar *SGD con momentum*, *RMSProp*, *AdamW*, entre otros, gestionando de forma cuidadosa la tasa de aprendizaje para evitar la explosión de gradientes.\n",
    "\n",
    "4. **Ampliación de métricas de evaluación**  \n",
    "   - Además de MSE y MAE, podría estudiarse *RMSE*, *R2* y otras específicas de color (p. ej., ΔE 2000) en caso de ser prioritaria la percepción visual.\n",
    "\n",
    "5. **Revisión pormenorizada de la generación sintética**  \n",
    "   - Dedicando más esfuerzo a la simulación de cambios de color, la introducción de ciclos propios de la producción real y la disminución del ruido se conseguirían datos más representativos.  \n",
    "   - En este proyecto, no se destinó tanto tiempo a esa tarea porque no era el objetivo principal.\n",
    "\n",
    "6. **Optimización del entrenamiento en Transformers**  \n",
    "   - Utilizar *mini-batches* y *mixed precision* para reducir costes computacionales, sobre todo al ampliar el *window size*.\n",
    "\n",
    "7. **Validación temporal escalonada**  \n",
    "   - En lugar de emplear únicamente la división 80/10/10, resulta recomendable un procedimiento “walk-forward” o “rolling window” que reproduzca mejor la dinámica real de la producción.\n",
    "\n",
    "8. **Exploración de enfoques modernos**  \n",
    "   - Modelos como GPT o Deepseek, pese a su orientación inicial, podrían adaptarse al entrenamiento con datos sintéticos y ofrecer mejoras.\n",
    "\n",
    "9. **Aplicación de técnicas avanzadas**  \n",
    "   - Una vez se disponga de un modelo suficientemente adaptable, se valoraría el *transfer learning* y el *fine-tuning* para ajustar un modelo base a diferentes máquinas de impresión con menor necesidad de datos y tiempos de puesta en producción más rápidos.\n",
    "\n",
    "10. **Sistemas híbridos**  \n",
    "   - Se contempla la posibilidad de combinar varios enfoques, aprovechando las ventajas de cada uno.  \n",
    "   - Un ejemplo es el uso de un *Transformer encoder* para extraer características globales y una capa GRU adicional para refinar patrones de corto plazo.\n",
    "\n",
    "11. **Variación en el desfase temporal**  \n",
    "   - Se recomienda investigar la predicción con horizontes distintos (p. ej., 2, 6 o 10 pasos) en lugar de usar únicamente 4, y estudiar cómo responde cada modelo ante dichos intervalos.\n",
    "\n",
    "---\n",
    "\n",
    "<a name=\"leccionesaprendidas\"></a>\n",
    "## Lecciones Aprendidas\n",
    "\n",
    "1. **Control de semillas y reproducibilidad**  \n",
    "   - Conviene establecer semillas en las librerías principales (TensorFlow/PyTorch, NumPy, CUDA) y documentar la configuración de hardware. Aun así, el comportamiento no se vuelve plenamente determinista.\n",
    "\n",
    "2. **Uso de `float32` y ventajas de *mixed precision***  \n",
    "   - Emplear precisión en `float32` (o *mixed precision*) reduce la memoria en GPU y acelera el entrenamiento, en especial en redes de gran tamaño.\n",
    "\n",
    "3. **Comparaciones entre frameworks**  \n",
    "   - Implementar modelos en PyTorch y TensorFlow simultáneamente conlleva un sobreesfuerzo, pero aumenta la flexibilidad para elegir la herramienta más conveniente.\n",
    "\n",
    "4. **Importancia del tamaño de ventana (window size)**  \n",
    "   - Determinar la ventana más adecuada depende del tipo de datos y de su periodicidad. Un análisis exploratorio minucioso puede revelar ciclos diarios o semanales relevantes.\n",
    "\n",
    "5. **Inestabilidad de drivers en Windows**  \n",
    "   - El uso de CUDA/cuDNN en Windows puede presentar errores o cierres inesperados, mientras que en Linux normalmente se logra una mayor estabilidad.\n",
    "\n",
    "6. **Pérdida de rendimiento al forzar determinismo en GPU**  \n",
    "   - Activar el modo determinista en cuDNN puede ralentizar el entrenamiento de forma significativa, lo que reduce la eficiencia en proyectos de gran escala.\n",
    "\n",
    "7. **Organización y registro de experimentos**  \n",
    "   - Mantener un historial detallado de los cambios en el código, los hiperparámetros y los datos facilita la comparación de resultados y evita inconsistencias.\n",
    "\n",
    "8. **Evitar un *overfitting* drástico**  \n",
    "   - En este proyecto, se aplicaron tasas de *dropout* elevadas (hasta 70%) para contrarrestar la aleatoriedad sintética, aunque lo más efectivo sería aumentar el tamaño de la muestra para mejorar la representatividad.\n",
    "\n",
    "9. **Early Stopping e hiperparámetros como factores clave**  \n",
    "   - Un *early stopping* excesivamente restrictivo puede truncar el aprendizaje; uno demasiado relajado puede llevar a sobreajuste y a errores de tipo NaN si el *learning rate* es elevado.\n",
    "\n",
    "10. **Tiempo y velocidad de proceso**  \n",
    "   - La velocidad de procesamiento determina cuántas pruebas se pueden realizar en un tiempo dado. Por ello, contar con hardware potente es esencial para refinar modelos de forma rápida y exhaustiva.\n",
    "\n",
    "11. **Herramientas avanzadas para el análisis de resultados**  \n",
    "   - Ha resultado complejo extraer conclusiones únicamente con las tablas y gráficos empleados. El uso de métodos de análisis más automatizados puede ahorrar tiempo y aportar mayor claridad.\n",
    "\n",
    "12. **Necesidad de mayor plazo**  \n",
    "   - Realizar todas las tareas en solo dos meses ha dificultado un desarrollo exhaustivo y menos productivo de lo esperado, pero ha servido para adquirir experiencia valiosa en la estimación de tiempos.\n",
    "\n",
    "---\n",
    "\n",
    "<a name=\"informeejecutivo\"></a>\n",
    "## **Informe Ejecutivo**\n",
    "\n",
    "La **principal conclusión** del estudio es que se requieren **más datos reales** para lograr modelos predictivos robustos en la impresión industrial sobre plástico. Hasta ahora, se han empleado datos sintéticos con resultados prometedores, pero no aptos para la producción. El tamaño de ventana, la metodología de entrenamiento (RNN, LSTM, GRU o Transformers) y la regularización (dropout, early stopping, etc.) se han explorado para mitigar el sobreajuste y mejorar la precisión. Sin embargo, sin validación con datos reales, no puede determinarse un enfoque “ganador”.\n",
    "\n",
    "**Puntos clave:**\n",
    "- **Ampliar histórico de datos o incrementar frecuencia de medición**: Los algoritmos secuenciales exigen grandes cantidades de información para aprender patrones. Cuantos más datos se manejen, mas recursos se requieren.\n",
    "- **Evaluar variables ambientales**: Factores como temperatura y humedad inciden en la calidad del color y podrían mejorar la predicción.  \n",
    "- **Transformers con más datos**: Su potencial supera a RNN y LSTM en ciertos casos, pero requieren muestras muy extensas y potencia de cómputo.  \n",
    "- **Trabajo futuro**: Ajuste y validación real con datos de producción industrial, incorporación de nuevas métricas de color y enfoques híbridos para incrementar la precisión.  \n",
    "\n",
    "En conclusión, **las investigaciones realizadas constituyen un primer paso prometedor**, pero se aconseja seguir obteniendo datos genuinos de las máquinas para refinar los modelos y llevarlos a un entorno productivo con confianza.\n",
    "\n",
    "---\n",
    "\n",
    "<!-- Sección 9: Bibliografía y Recursos -->\n",
    "<a name=\"bibliografiayrecursos\"></a>\n",
    "# **9. Bibliografía y Recursos**\n",
    "\n",
    "* **CIELAB**: https://es.wikipedia.org/wiki/Espacio_de_color_Lab\n",
    "* **Estandar ISO 17972-1:2015**: https://www.iso.org/standard/61500.html\n",
    "* **AEMET**: https://www.aemet.es/\n",
    "* **Comparativa de optimizadores**: https://antonio-richaud.com/biblioteca/archivo/Algoritmos-de-optimizacion-para-RN/Algoritmos-de-optimizacion-para-RN.pdf\n",
    "* **LLMs**: ChatGpt, Deepseek entre otros.\n",
    "* **Pytorch**: https://pytorch.org/\n",
    "* **Tensorflow**: https://www.tensorflow.org/?hl=es\n",
    "---\n",
    "\n",
    "<!-- Sección 10: Anexos -->\n",
    "<a name=\"anexos\"></a>\n",
    "# **10. Anexos**  \n",
    "\n",
    "- [Repositorio de código](https://github.com/laperl/MasterIA): Contiene todo el código fuente del proyecto, desde la adquisición de datos hasta el análisis de resultados.\n",
    "\n",
    "  - [📄 Esta memoria](https://github.com/laperl/MasterIA/blob/main/00_MemoriaFinal.ipynb): Documento principal con la descripción del proyecto, metodología y resultados.\n",
    "  - [🌦️ 01_DatosMeteorologicos.ipynb](https://github.com/laperl/MasterIA/blob/main/01_DatosMeteorologicos.ipynb): Obtención y análisis de datos meteorológicos de AENET para evaluar su impacto en la predicción del color LAB.\n",
    "  - [🛠️ 02_generador_datos_sinteticos.ipynb](https://github.com/laperl/MasterIA/blob/main/02_generador_datos_sinteticos.ipynb): Algoritmo para generar datos sintéticos simulando condiciones reales de impresión.\n",
    "  - [📊 03_AnalisisDeDatos.ipynb](https://github.com/laperl/MasterIA/blob/main/03_AnalisisDeDatos.ipynb): Exploración y transformación de los datos para su uso en modelos de predicción.\n",
    "  - [🔄 04_ArreglosFinalesDatos.ipynb](https://github.com/laperl/MasterIA/blob/main/04_ArreglosFinalesDatos.ipynb): Preparación final de los datos, incluyendo la división en conjuntos de entrenamiento, validación y prueba.\n",
    "  - [🤖 05a_ModeloRNN-DirectApproach.ipynb](https://github.com/laperl/MasterIA/blob/main/05a_ModeloRNN-DirectApproach.ipynb): Implementación de modelos basados en **GRU y LSTM**, con pruebas de hiperparámetros.\n",
    "  - [⚡ 05b_Transformers.ipynb](https://github.com/laperl/MasterIA/blob/main/05b_Transformers.ipynb): Desarrollo de modelos **basados en Transformers**, junto con visualización de resultados.\n",
    "  - [📉 06_AnalisiResultados_RNN.ipynb](https://github.com/laperl/MasterIA/blob/main/06_AnalisiResultados_RNN.ipynb): Análisis y comparación del rendimiento de modelos **RNN (LSTM / GRU)**.\n",
    "  - [🔮 07_Predicciones.ipynb](https://github.com/laperl/MasterIA/blob/main/07_Predicciones.ipynb): Visualización de predicciones y comparación con valores reales para evaluar la efectividad de los modelos.\n",
    "- 📹 [Link al video explicativo](https://drive.google.com/file/d/1TCzMvuu-g2_156ussxLOw_upSpv5JgsB/view?usp=drive_link): Resumen en video sobre la metodología y conclusiones del proyecto.\n",
    "- 🖼️ [Imágenes y resultados](https://github.com/laperl/MasterIA/tree/main/Resultados): Visualización de datos, gráficos comparativos y ejemplos de predicciones.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce64de0a-9373-4444-a16e-9a282f567469",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
