{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "957bc431-29b6-4cba-81c1-1f3735ac34e6",
   "metadata": {},
   "source": [
    "# División de muestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d65e2207-5d63-441b-b578-6e9137a18a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d683de0-f3f3-485a-81da-19a29e0f7033",
   "metadata": {},
   "source": [
    "# Variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8450b437-62c9-4e36-84e4-4fa53329d374",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIC_ENTRADA='data_and_scaler.joblib'\n",
    "RUTA_FICHEROS = r\"C:\\Users\\jaume\\Documents\\Proyecto\\datos\"\n",
    "FIC_SALIDA='train_test_val_scaler.joblib'\n",
    "\n",
    "# Porcentajes para cada muestra\n",
    "TAMANO_VALIDACION=0.1\n",
    "TAMANO_TEST=0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1d6fdbd-58a6-4e54-826e-c51965794541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "os.chdir(RUTA_FICHEROS)\n",
    "\n",
    "with open(FIC_ENTRADA, 'rb') as file:\n",
    "    data_dict = joblib.load(file)\n",
    "\n",
    "# Recuperar DataFrame y scaler\n",
    "df_normalizado = data_dict['dataframe'].copy()  # Este DF contiene las columnas *_scaled, dummies, etc.\n",
    "scaler = data_dict['scaler']              # Contiene las normalizaciones con StandarScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c3cbf0-3d3e-4fd6-977a-102a135afcf1",
   "metadata": {},
   "source": [
    "# Dididir Train/Test/Val\n",
    "\n",
    "Dividiré en 80% para Train, 10% para Validación y 10% para Test.\n",
    "\n",
    "\"Test\" sólo lo usaré al final de todo así estarán totalmente aisladas.\n",
    "\n",
    "Evidentemente en mi caso no puedo usar \"shuffle\" dado que son RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e5aee27-0cb1-4b73-bf04-74449d8b4880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_time_series(df, test_size=0.1, val_size=0.1):\n",
    "    \"\"\"\n",
    "    Divide un DataFrame en conjuntos de entrenamiento, validación y prueba,\n",
    "    manteniendo el orden temporal de los datos (sin shuffle).\n",
    "    \n",
    "    Parámetros:\n",
    "        df (pd.DataFrame): DataFrame a dividir.\n",
    "        test_size (float): Proporción de datos para el conjunto de prueba.\n",
    "        val_size (float): Proporción de datos para el conjunto de validación.\n",
    "    \n",
    "    Retorna:\n",
    "        df_train (pd.DataFrame): Conjunto de entrenamiento.\n",
    "        df_val (pd.DataFrame): Conjunto de validación.\n",
    "        df_test (pd.DataFrame): Conjunto de prueba.\n",
    "    \"\"\"\n",
    "    # Definir tamaños en términos absolutos\n",
    "    total_size = len(df)\n",
    "    test_abs = int(total_size * test_size)\n",
    "    val_abs = int(total_size * val_size)\n",
    "\n",
    "    # División respetando el orden temporal\n",
    "    df_train = df.iloc[:-test_abs-val_abs]  # Entrenamiento hasta antes de validación y test\n",
    "    df_val = df.iloc[-test_abs-val_abs:-test_abs]  # Validación antes de test\n",
    "    df_test = df.iloc[-test_abs:]  # Test al final\n",
    "\n",
    "    return df_train, df_val, df_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52ab31c6-8fc3-46f2-bcc5-e1999ecc31db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño Train: 216768, Validación: 27095, Test: 27095\n"
     ]
    }
   ],
   "source": [
    "# Aplicamos la función con 10% test y 10% validación\n",
    "df_train, df_val, df_test = split_time_series(df_normalizado, test_size=TAMANO_TEST, val_size=TAMANO_VALIDACION)\n",
    "\n",
    "# Mostramos los tamaños\n",
    "print(f\"Tamaño Train: {len(df_train)}, Validación: {len(df_val)}, Test: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1de7c62-6d91-4928-833a-c5787261d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar en un archivo\n",
    "os.chdir(RUTA_FICHEROS)\n",
    "\n",
    "with open(FIC_SALIDA, 'wb') as file:\n",
    "    joblib.dump({'train': df_train, 'test': df_test, 'val': df_val, 'scaler': scaler}, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06575cc-647e-4404-a282-920cd6c84c52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a13d1d-c876-40e9-80d9-4ea21719e15c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c151d41-1b22-42aa-857d-dc2c17de2a21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
